{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Reshape, GlobalAveragePooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    df = pd.read_csv(file_path, index_col=[0])\n",
    "    # df['f1d_binary'] = np.where(df['f1d_label'] > 0, 1, 0)\n",
    "\n",
    "    df_stock = df[df['minor'] == 'VMC'][['minor', 'Date', '0', '1', '2', 'f1d_label']]\n",
    "    return df_stock\n",
    "\n",
    "\n",
    "def create_segments_and_labels(df, time_steps, step, label_name):\n",
    "    # Number of steps to advance in each iteration\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['0'].values[i: i + time_steps]\n",
    "        ys = df['1'].values[i: i + time_steps]\n",
    "        zs = df['2'].values[i: i + time_steps]\n",
    "\n",
    "        # use last days f1d_binary as label\n",
    "        label = df[label_name].values[i + time_steps - 1]\n",
    "\n",
    "        # # for testing\n",
    "        # from numpy import random\n",
    "        # label = random.randint(2)\n",
    "\n",
    "        segments.append([xs, ys, zs])\n",
    "        labels.append(label)\n",
    "\n",
    "    # Bring the segments into a better shape\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '/Users/kaiwang/bkup/har-keras-cnn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''params'''\n",
    "# n features\n",
    "N_FEATURES = 3\n",
    "\n",
    "# The number of steps within one time segment\n",
    "TIME_PERIODS = 60\n",
    "# The steps to take from one segment to the next; if this value is equal to\n",
    "# TIME_PERIODS, then there is no overlap between the segments\n",
    "STEP_DISTANCE = 1\n",
    "\n",
    "filter_height = 3\n",
    "filter_depths = [2, 4, 8, 16]\n",
    "drop_out = 0.5\n",
    "\n",
    "# Hyper-parameters\n",
    "BATCH_SIZE = 400\n",
    "EPOCHS = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Reshape the data into segments ---\n",
      "\n",
      "\n",
      "--- Reshape data to be accepted by Keras ---\n",
      "\n",
      "('x_train shape: ', (5360, 60, 3))\n",
      "(5360, 'training samples')\n",
      "('y_train shape: ', (5360,))\n"
     ]
    }
   ],
   "source": [
    "df = read_data(root_folder + 'Data/temp_ret_3_30_stocks.csv')\n",
    "\n",
    "# Define column name of the label vector\n",
    "# LABEL = 'f1d_binary'\n",
    "LABEL = 'f1d_label'\n",
    "\n",
    "print(\"\\n--- Reshape the data into segments ---\\n\")\n",
    "\n",
    "# Differentiate between test set and training set\n",
    "df_test = df[df['Date'] > '2019-02-24T09:30:00Z']\n",
    "df_train = df[df['Date'] <= '2019-02-24T09:30:00Z']\n",
    "\n",
    "# Reshape the training data into segments\n",
    "# so that they can be processed by the network\n",
    "x_train, y_train = create_segments_and_labels(df_train,\n",
    "                                              TIME_PERIODS,\n",
    "                                              STEP_DISTANCE,\n",
    "                                              LABEL)\n",
    "\n",
    "print(\"\\n--- Reshape data to be accepted by Keras ---\\n\")\n",
    "\n",
    "# Inspect x data\n",
    "print('x_train shape: ', x_train.shape)\n",
    "# Displays (134, 80, 3)\n",
    "print(x_train.shape[0], 'training samples')\n",
    "# Displays 134 train samples\n",
    "\n",
    "# Inspect y data\n",
    "print('y_train shape: ', y_train.shape)\n",
    "# Displays (134,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (5360, 180))\n",
      "('input_shape:', 180)\n"
     ]
    }
   ],
   "source": [
    "# Set input & output dimensions\n",
    "num_time_periods, num_features = x_train.shape[1], x_train.shape[2]\n",
    "num_classes = 2\n",
    "\n",
    "# Set input_shape / reshape for Keras\n",
    "# todo: remove\n",
    "# Remark: acceleration data is concatenated in one array in order to feed\n",
    "# it properly into coreml later, the preferred matrix of shape [80,3]\n",
    "# cannot be read in with the current version of coreml (see also reshape\n",
    "# layer as the first layer in the keras model)\n",
    "input_shape = (num_time_periods * num_features)\n",
    "x_train = x_train.reshape(x_train.shape[0], input_shape)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "# x_train shape: (20869, 240)\n",
    "print('input_shape:', input_shape)\n",
    "# input_shape: (240)\n",
    "\n",
    "# Convert type for Keras otherwise Keras cannot process the data\n",
    "x_train = x_train.astype(\"float32\")\n",
    "y_train = y_train.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Create neural network model ---\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_2 (Reshape)          (None, 60, 3)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 58, 2)             20        \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 56, 4)             28        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 18, 4)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16, 8)             104       \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 14, 16)            400       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 569\n",
      "Trainable params: 569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "--- Fit the model ---\n",
      "\n",
      "Train on 4288 samples, validate on 1072 samples\n",
      "Epoch 1/600\n",
      "4288/4288 [==============================] - 1s 144us/step - loss: 1.5482e-05 - val_loss: 3.6141e-06\n",
      "Epoch 2/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5394e-05 - val_loss: 3.5763e-06\n",
      "Epoch 3/600\n",
      " 400/4288 [=>............................] - ETA: 0s - loss: 1.4800e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaiwang/venv/lib/python2.7/site-packages/keras/callbacks.py:535: RuntimeWarning: Early stopping conditioned on metric `acc` which is not available. Available metrics are: loss,val_loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5224e-05 - val_loss: 3.5906e-06\n",
      "Epoch 4/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5147e-05 - val_loss: 3.5510e-06\n",
      "Epoch 5/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5251e-05 - val_loss: 3.5588e-06\n",
      "Epoch 6/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5273e-05 - val_loss: 3.5374e-06\n",
      "Epoch 7/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5258e-05 - val_loss: 3.5794e-06\n",
      "Epoch 8/600\n",
      "4288/4288 [==============================] - 0s 31us/step - loss: 1.5194e-05 - val_loss: 3.5724e-06\n",
      "Epoch 9/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5214e-05 - val_loss: 3.6022e-06\n",
      "Epoch 10/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5190e-05 - val_loss: 3.5895e-06\n",
      "Epoch 11/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5282e-05 - val_loss: 3.7005e-06\n",
      "Epoch 12/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5197e-05 - val_loss: 3.7747e-06\n",
      "Epoch 13/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5153e-05 - val_loss: 3.5898e-06\n",
      "Epoch 14/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5160e-05 - val_loss: 3.7008e-06\n",
      "Epoch 15/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5199e-05 - val_loss: 3.7774e-06\n",
      "Epoch 16/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5164e-05 - val_loss: 3.6424e-06\n",
      "Epoch 17/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5198e-05 - val_loss: 3.6002e-06\n",
      "Epoch 18/600\n",
      "4288/4288 [==============================] - 0s 34us/step - loss: 1.5183e-05 - val_loss: 3.6139e-06\n",
      "Epoch 19/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5243e-05 - val_loss: 3.7742e-06\n",
      "Epoch 20/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5164e-05 - val_loss: 3.6345e-06\n",
      "Epoch 21/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5231e-05 - val_loss: 3.5609e-06\n",
      "Epoch 22/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5122e-05 - val_loss: 3.6254e-06\n",
      "Epoch 23/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5120e-05 - val_loss: 3.6417e-06\n",
      "Epoch 24/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5285e-05 - val_loss: 3.7084e-06\n",
      "Epoch 25/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5223e-05 - val_loss: 3.6038e-06\n",
      "Epoch 26/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5233e-05 - val_loss: 3.5414e-06\n",
      "Epoch 27/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5370e-05 - val_loss: 3.6555e-06\n",
      "Epoch 28/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5246e-05 - val_loss: 4.0469e-06\n",
      "Epoch 29/600\n",
      "4288/4288 [==============================] - 0s 35us/step - loss: 1.5205e-05 - val_loss: 4.0855e-06\n",
      "Epoch 30/600\n",
      "4288/4288 [==============================] - 0s 33us/step - loss: 1.5323e-05 - val_loss: 4.0396e-06\n",
      "Epoch 31/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5269e-05 - val_loss: 3.5545e-06\n",
      "Epoch 32/600\n",
      "4288/4288 [==============================] - 0s 33us/step - loss: 1.5168e-05 - val_loss: 3.5784e-06\n",
      "Epoch 33/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5259e-05 - val_loss: 3.5729e-06\n",
      "Epoch 34/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5197e-05 - val_loss: 3.5386e-06\n",
      "Epoch 35/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5223e-05 - val_loss: 3.6902e-06\n",
      "Epoch 36/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5163e-05 - val_loss: 3.8625e-06\n",
      "Epoch 37/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5423e-05 - val_loss: 4.3005e-06\n",
      "Epoch 38/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5470e-05 - val_loss: 4.5329e-06\n",
      "Epoch 39/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5383e-05 - val_loss: 4.1731e-06\n",
      "Epoch 40/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5297e-05 - val_loss: 3.9854e-06\n",
      "Epoch 41/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5259e-05 - val_loss: 3.9222e-06\n",
      "Epoch 42/600\n",
      "4288/4288 [==============================] - 0s 33us/step - loss: 1.5279e-05 - val_loss: 3.7254e-06\n",
      "Epoch 43/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5159e-05 - val_loss: 3.7845e-06\n",
      "Epoch 44/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5182e-05 - val_loss: 4.1062e-06\n",
      "Epoch 45/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5315e-05 - val_loss: 3.6168e-06\n",
      "Epoch 46/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5311e-05 - val_loss: 3.5664e-06\n",
      "Epoch 47/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5213e-05 - val_loss: 3.9942e-06\n",
      "Epoch 48/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5158e-05 - val_loss: 3.9900e-06\n",
      "Epoch 49/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5171e-05 - val_loss: 3.6469e-06\n",
      "Epoch 50/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5119e-05 - val_loss: 3.6005e-06\n",
      "Epoch 51/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5191e-05 - val_loss: 3.5797e-06\n",
      "Epoch 52/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5179e-05 - val_loss: 3.6241e-06\n",
      "Epoch 53/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5225e-05 - val_loss: 3.5755e-06\n",
      "Epoch 54/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5248e-05 - val_loss: 3.5914e-06\n",
      "Epoch 55/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5175e-05 - val_loss: 3.6088e-06\n",
      "Epoch 56/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5209e-05 - val_loss: 3.6003e-06\n",
      "Epoch 57/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5288e-05 - val_loss: 3.7664e-06\n",
      "Epoch 58/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5172e-05 - val_loss: 3.6276e-06\n",
      "Epoch 59/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5155e-05 - val_loss: 3.6844e-06\n",
      "Epoch 60/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5166e-05 - val_loss: 3.6971e-06\n",
      "Epoch 61/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5130e-05 - val_loss: 3.5523e-06\n",
      "Epoch 62/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5263e-05 - val_loss: 3.5975e-06\n",
      "Epoch 63/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5273e-05 - val_loss: 3.6938e-06\n",
      "Epoch 64/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5213e-05 - val_loss: 3.8012e-06\n",
      "Epoch 65/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5213e-05 - val_loss: 3.7448e-06\n",
      "Epoch 66/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5155e-05 - val_loss: 3.7501e-06\n",
      "Epoch 67/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5161e-05 - val_loss: 3.6020e-06\n",
      "Epoch 68/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5264e-05 - val_loss: 3.5564e-06\n",
      "Epoch 69/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5239e-05 - val_loss: 3.5710e-06\n",
      "Epoch 70/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5174e-05 - val_loss: 3.5413e-06\n",
      "Epoch 71/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5219e-05 - val_loss: 3.7134e-06\n",
      "Epoch 72/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5153e-05 - val_loss: 3.6641e-06\n",
      "Epoch 73/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5145e-05 - val_loss: 3.8593e-06\n",
      "Epoch 74/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5171e-05 - val_loss: 3.8419e-06\n",
      "Epoch 75/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5170e-05 - val_loss: 3.6658e-06\n",
      "Epoch 76/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5164e-05 - val_loss: 3.6639e-06\n",
      "Epoch 77/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5232e-05 - val_loss: 3.5520e-06\n",
      "Epoch 78/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5308e-05 - val_loss: 3.5527e-06\n",
      "Epoch 79/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5361e-05 - val_loss: 3.5411e-06\n",
      "Epoch 80/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5264e-05 - val_loss: 3.5693e-06\n",
      "Epoch 81/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5123e-05 - val_loss: 3.6041e-06\n",
      "Epoch 82/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5218e-05 - val_loss: 3.7602e-06\n",
      "Epoch 83/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5154e-05 - val_loss: 3.7032e-06\n",
      "Epoch 84/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5200e-05 - val_loss: 3.8728e-06\n",
      "Epoch 85/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5160e-05 - val_loss: 3.6745e-06\n",
      "Epoch 86/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5189e-05 - val_loss: 3.6454e-06\n",
      "Epoch 87/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5203e-05 - val_loss: 3.8783e-06\n",
      "Epoch 88/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5178e-05 - val_loss: 3.7705e-06\n",
      "Epoch 89/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5159e-05 - val_loss: 3.6674e-06\n",
      "Epoch 90/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5181e-05 - val_loss: 3.7384e-06\n",
      "Epoch 91/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5218e-05 - val_loss: 3.7198e-06\n",
      "Epoch 92/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5341e-05 - val_loss: 3.5413e-06\n",
      "Epoch 93/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5293e-05 - val_loss: 3.5399e-06\n",
      "Epoch 94/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5154e-05 - val_loss: 3.5627e-06\n",
      "Epoch 95/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5115e-05 - val_loss: 3.6709e-06\n",
      "Epoch 96/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5170e-05 - val_loss: 3.9066e-06\n",
      "Epoch 97/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5218e-05 - val_loss: 3.5619e-06\n",
      "Epoch 98/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5147e-05 - val_loss: 3.5531e-06\n",
      "Epoch 99/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5124e-05 - val_loss: 3.6318e-06\n",
      "Epoch 100/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5157e-05 - val_loss: 4.1207e-06\n",
      "Epoch 101/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5309e-05 - val_loss: 3.7080e-06\n",
      "Epoch 102/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5197e-05 - val_loss: 3.5726e-06\n",
      "Epoch 103/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5153e-05 - val_loss: 3.8048e-06\n",
      "Epoch 104/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5134e-05 - val_loss: 3.9339e-06\n",
      "Epoch 105/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5279e-05 - val_loss: 3.6850e-06\n",
      "Epoch 106/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5160e-05 - val_loss: 3.5657e-06\n",
      "Epoch 107/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5236e-05 - val_loss: 3.6110e-06\n",
      "Epoch 108/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5163e-05 - val_loss: 3.5819e-06\n",
      "Epoch 109/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5265e-05 - val_loss: 3.6642e-06\n",
      "Epoch 110/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5279e-05 - val_loss: 3.9732e-06\n",
      "Epoch 111/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5213e-05 - val_loss: 3.6225e-06\n",
      "Epoch 112/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5135e-05 - val_loss: 3.6484e-06\n",
      "Epoch 113/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5101e-05 - val_loss: 3.6692e-06\n",
      "Epoch 114/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5134e-05 - val_loss: 3.9423e-06\n",
      "Epoch 115/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5164e-05 - val_loss: 4.2736e-06\n",
      "Epoch 116/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5293e-05 - val_loss: 4.6242e-06\n",
      "Epoch 117/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5495e-05 - val_loss: 4.1896e-06\n",
      "Epoch 118/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5220e-05 - val_loss: 3.9892e-06\n",
      "Epoch 119/600\n",
      "4288/4288 [==============================] - 0s 31us/step - loss: 1.5201e-05 - val_loss: 3.5626e-06\n",
      "Epoch 120/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5187e-05 - val_loss: 3.6227e-06\n",
      "Epoch 121/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5126e-05 - val_loss: 3.6052e-06\n",
      "Epoch 122/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5141e-05 - val_loss: 3.6688e-06\n",
      "Epoch 123/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5143e-05 - val_loss: 3.8098e-06\n",
      "Epoch 124/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5104e-05 - val_loss: 3.6017e-06\n",
      "Epoch 125/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5147e-05 - val_loss: 3.8172e-06\n",
      "Epoch 126/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5136e-05 - val_loss: 3.8081e-06\n",
      "Epoch 127/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5180e-05 - val_loss: 4.1765e-06\n",
      "Epoch 128/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5301e-05 - val_loss: 3.9279e-06\n",
      "Epoch 129/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5316e-05 - val_loss: 3.7873e-06\n",
      "Epoch 130/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5217e-05 - val_loss: 4.2416e-06\n",
      "Epoch 131/600\n",
      "4288/4288 [==============================] - 0s 36us/step - loss: 1.5162e-05 - val_loss: 3.9483e-06\n",
      "Epoch 132/600\n",
      "4288/4288 [==============================] - 0s 35us/step - loss: 1.5112e-05 - val_loss: 3.5604e-06\n",
      "Epoch 133/600\n",
      "4288/4288 [==============================] - 0s 35us/step - loss: 1.5355e-05 - val_loss: 3.5401e-06\n",
      "Epoch 134/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5210e-05 - val_loss: 3.5632e-06\n",
      "Epoch 135/600\n",
      "4288/4288 [==============================] - 0s 31us/step - loss: 1.5191e-05 - val_loss: 3.8854e-06\n",
      "Epoch 136/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5195e-05 - val_loss: 4.1671e-06\n",
      "Epoch 137/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5223e-05 - val_loss: 4.1898e-06\n",
      "Epoch 138/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5323e-05 - val_loss: 3.9122e-06\n",
      "Epoch 139/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5131e-05 - val_loss: 3.8501e-06\n",
      "Epoch 140/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5125e-05 - val_loss: 3.7924e-06\n",
      "Epoch 141/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5191e-05 - val_loss: 3.7158e-06\n",
      "Epoch 142/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5195e-05 - val_loss: 3.6411e-06\n",
      "Epoch 143/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5159e-05 - val_loss: 3.7366e-06\n",
      "Epoch 144/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5173e-05 - val_loss: 3.5402e-06\n",
      "Epoch 145/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5230e-05 - val_loss: 3.5446e-06\n",
      "Epoch 146/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5233e-05 - val_loss: 3.5865e-06\n",
      "Epoch 147/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5236e-05 - val_loss: 3.6574e-06\n",
      "Epoch 148/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5203e-05 - val_loss: 3.7769e-06\n",
      "Epoch 149/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5208e-05 - val_loss: 3.9080e-06\n",
      "Epoch 150/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5135e-05 - val_loss: 3.6719e-06\n",
      "Epoch 151/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5128e-05 - val_loss: 3.7373e-06\n",
      "Epoch 152/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5122e-05 - val_loss: 3.6241e-06\n",
      "Epoch 153/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5188e-05 - val_loss: 3.5496e-06\n",
      "Epoch 154/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5119e-05 - val_loss: 3.5562e-06\n",
      "Epoch 155/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5169e-05 - val_loss: 3.5437e-06\n",
      "Epoch 156/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5170e-05 - val_loss: 3.6597e-06\n",
      "Epoch 157/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5125e-05 - val_loss: 3.6028e-06\n",
      "Epoch 158/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5172e-05 - val_loss: 3.6069e-06\n",
      "Epoch 159/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5103e-05 - val_loss: 3.6546e-06\n",
      "Epoch 160/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5117e-05 - val_loss: 3.5911e-06\n",
      "Epoch 161/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5225e-05 - val_loss: 3.5405e-06\n",
      "Epoch 162/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5268e-05 - val_loss: 3.5435e-06\n",
      "Epoch 163/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5208e-05 - val_loss: 3.5442e-06\n",
      "Epoch 164/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5166e-05 - val_loss: 3.7453e-06\n",
      "Epoch 165/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5151e-05 - val_loss: 3.7247e-06\n",
      "Epoch 166/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5189e-05 - val_loss: 3.5628e-06\n",
      "Epoch 167/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5185e-05 - val_loss: 3.5518e-06\n",
      "Epoch 168/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5283e-05 - val_loss: 3.7272e-06\n",
      "Epoch 169/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5224e-05 - val_loss: 3.5524e-06\n",
      "Epoch 170/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5260e-05 - val_loss: 3.5509e-06\n",
      "Epoch 171/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5291e-05 - val_loss: 3.5435e-06\n",
      "Epoch 172/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5352e-05 - val_loss: 3.5583e-06\n",
      "Epoch 173/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5289e-05 - val_loss: 3.5736e-06\n",
      "Epoch 174/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5225e-05 - val_loss: 3.5735e-06\n",
      "Epoch 175/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5189e-05 - val_loss: 3.6196e-06\n",
      "Epoch 176/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5214e-05 - val_loss: 3.5569e-06\n",
      "Epoch 177/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5255e-05 - val_loss: 3.5481e-06\n",
      "Epoch 178/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5208e-05 - val_loss: 3.6551e-06\n",
      "Epoch 179/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5244e-05 - val_loss: 3.6336e-06\n",
      "Epoch 180/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5184e-05 - val_loss: 3.7795e-06\n",
      "Epoch 181/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5177e-05 - val_loss: 3.7848e-06\n",
      "Epoch 182/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5174e-05 - val_loss: 3.6215e-06\n",
      "Epoch 183/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5153e-05 - val_loss: 3.6634e-06\n",
      "Epoch 184/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5194e-05 - val_loss: 3.5996e-06\n",
      "Epoch 185/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5180e-05 - val_loss: 4.0339e-06\n",
      "Epoch 186/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5126e-05 - val_loss: 3.9334e-06\n",
      "Epoch 187/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5236e-05 - val_loss: 3.9791e-06\n",
      "Epoch 188/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5211e-05 - val_loss: 4.0186e-06\n",
      "Epoch 189/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5166e-05 - val_loss: 3.6214e-06\n",
      "Epoch 190/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5220e-05 - val_loss: 3.7592e-06\n",
      "Epoch 191/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5330e-05 - val_loss: 3.9801e-06\n",
      "Epoch 192/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5238e-05 - val_loss: 3.6114e-06\n",
      "Epoch 193/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5197e-05 - val_loss: 3.5731e-06\n",
      "Epoch 194/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5144e-05 - val_loss: 3.7900e-06\n",
      "Epoch 195/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5161e-05 - val_loss: 3.5571e-06\n",
      "Epoch 196/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5140e-05 - val_loss: 3.6194e-06\n",
      "Epoch 197/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5245e-05 - val_loss: 3.5650e-06\n",
      "Epoch 198/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5242e-05 - val_loss: 3.6098e-06\n",
      "Epoch 199/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5256e-05 - val_loss: 3.5406e-06\n",
      "Epoch 200/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5058e-05 - val_loss: 3.5541e-06\n",
      "Epoch 201/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5156e-05 - val_loss: 3.8426e-06\n",
      "Epoch 202/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5155e-05 - val_loss: 3.8695e-06\n",
      "Epoch 203/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5159e-05 - val_loss: 3.6788e-06\n",
      "Epoch 204/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5176e-05 - val_loss: 3.5551e-06\n",
      "Epoch 205/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5384e-05 - val_loss: 3.5420e-06\n",
      "Epoch 206/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5216e-05 - val_loss: 3.5588e-06\n",
      "Epoch 207/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5122e-05 - val_loss: 3.7151e-06\n",
      "Epoch 208/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5174e-05 - val_loss: 3.7257e-06\n",
      "Epoch 209/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5152e-05 - val_loss: 3.6346e-06\n",
      "Epoch 210/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5137e-05 - val_loss: 3.7406e-06\n",
      "Epoch 211/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5211e-05 - val_loss: 4.1676e-06\n",
      "Epoch 212/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5327e-05 - val_loss: 4.2398e-06\n",
      "Epoch 213/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5317e-05 - val_loss: 4.1526e-06\n",
      "Epoch 214/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5169e-05 - val_loss: 3.5415e-06\n",
      "Epoch 215/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5208e-05 - val_loss: 3.5446e-06\n",
      "Epoch 216/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5191e-05 - val_loss: 3.6310e-06\n",
      "Epoch 217/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5066e-05 - val_loss: 3.5450e-06\n",
      "Epoch 218/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5218e-05 - val_loss: 3.6058e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5187e-05 - val_loss: 3.6984e-06\n",
      "Epoch 220/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5174e-05 - val_loss: 3.7798e-06\n",
      "Epoch 221/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5198e-05 - val_loss: 4.0223e-06\n",
      "Epoch 222/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5210e-05 - val_loss: 3.5672e-06\n",
      "Epoch 223/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5145e-05 - val_loss: 3.5622e-06\n",
      "Epoch 224/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5172e-05 - val_loss: 3.5879e-06\n",
      "Epoch 225/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5238e-05 - val_loss: 3.7271e-06\n",
      "Epoch 226/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5153e-05 - val_loss: 3.6913e-06\n",
      "Epoch 227/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5121e-05 - val_loss: 3.7176e-06\n",
      "Epoch 228/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5160e-05 - val_loss: 3.9722e-06\n",
      "Epoch 229/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5146e-05 - val_loss: 3.7142e-06\n",
      "Epoch 230/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5227e-05 - val_loss: 3.7879e-06\n",
      "Epoch 231/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5248e-05 - val_loss: 3.5496e-06\n",
      "Epoch 232/600\n",
      "4288/4288 [==============================] - 0s 18us/step - loss: 1.5301e-05 - val_loss: 3.6018e-06\n",
      "Epoch 233/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5179e-05 - val_loss: 3.5550e-06\n",
      "Epoch 234/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5213e-05 - val_loss: 3.6128e-06\n",
      "Epoch 235/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5171e-05 - val_loss: 3.5402e-06\n",
      "Epoch 236/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5325e-05 - val_loss: 3.5698e-06\n",
      "Epoch 237/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5166e-05 - val_loss: 3.6079e-06\n",
      "Epoch 238/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5124e-05 - val_loss: 3.6880e-06\n",
      "Epoch 239/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5193e-05 - val_loss: 3.6763e-06\n",
      "Epoch 240/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5099e-05 - val_loss: 3.7120e-06\n",
      "Epoch 241/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5118e-05 - val_loss: 3.6335e-06\n",
      "Epoch 242/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5176e-05 - val_loss: 3.8321e-06\n",
      "Epoch 243/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5147e-05 - val_loss: 3.6998e-06\n",
      "Epoch 244/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5107e-05 - val_loss: 3.5431e-06\n",
      "Epoch 245/600\n",
      "4288/4288 [==============================] - 0s 18us/step - loss: 1.5260e-05 - val_loss: 3.5559e-06\n",
      "Epoch 246/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5137e-05 - val_loss: 3.6239e-06\n",
      "Epoch 247/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5113e-05 - val_loss: 3.8512e-06\n",
      "Epoch 248/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5173e-05 - val_loss: 3.6823e-06\n",
      "Epoch 249/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5087e-05 - val_loss: 3.5399e-06\n",
      "Epoch 250/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5230e-05 - val_loss: 3.5417e-06\n",
      "Epoch 251/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5232e-05 - val_loss: 3.7157e-06\n",
      "Epoch 252/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5118e-05 - val_loss: 3.8116e-06\n",
      "Epoch 253/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5131e-05 - val_loss: 3.5715e-06\n",
      "Epoch 254/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5150e-05 - val_loss: 3.6083e-06\n",
      "Epoch 255/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5195e-05 - val_loss: 4.0779e-06\n",
      "Epoch 256/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5302e-05 - val_loss: 3.8797e-06\n",
      "Epoch 257/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5221e-05 - val_loss: 3.9391e-06\n",
      "Epoch 258/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5290e-05 - val_loss: 3.8411e-06\n",
      "Epoch 259/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5194e-05 - val_loss: 4.2719e-06\n",
      "Epoch 260/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5237e-05 - val_loss: 3.7535e-06\n",
      "Epoch 261/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5140e-05 - val_loss: 3.6175e-06\n",
      "Epoch 262/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5170e-05 - val_loss: 3.8107e-06\n",
      "Epoch 263/600\n",
      "4288/4288 [==============================] - 0s 40us/step - loss: 1.5178e-05 - val_loss: 3.6670e-06\n",
      "Epoch 264/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5150e-05 - val_loss: 3.7281e-06\n",
      "Epoch 265/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5165e-05 - val_loss: 3.6470e-06\n",
      "Epoch 266/600\n",
      "4288/4288 [==============================] - 0s 31us/step - loss: 1.5202e-05 - val_loss: 3.6457e-06\n",
      "Epoch 267/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5273e-05 - val_loss: 3.6260e-06\n",
      "Epoch 268/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5214e-05 - val_loss: 3.7220e-06\n",
      "Epoch 269/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5117e-05 - val_loss: 3.9649e-06\n",
      "Epoch 270/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5152e-05 - val_loss: 3.8456e-06\n",
      "Epoch 271/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5155e-05 - val_loss: 3.9846e-06\n",
      "Epoch 272/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5142e-05 - val_loss: 3.6827e-06\n",
      "Epoch 273/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5270e-05 - val_loss: 3.6273e-06\n",
      "Epoch 274/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5234e-05 - val_loss: 3.5827e-06\n",
      "Epoch 275/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5172e-05 - val_loss: 3.6514e-06\n",
      "Epoch 276/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5188e-05 - val_loss: 3.7114e-06\n",
      "Epoch 277/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5266e-05 - val_loss: 3.6081e-06\n",
      "Epoch 278/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5181e-05 - val_loss: 3.5554e-06\n",
      "Epoch 279/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5123e-05 - val_loss: 3.6902e-06\n",
      "Epoch 280/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5129e-05 - val_loss: 3.5937e-06\n",
      "Epoch 281/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5159e-05 - val_loss: 3.6120e-06\n",
      "Epoch 282/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5161e-05 - val_loss: 3.7136e-06\n",
      "Epoch 283/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5208e-05 - val_loss: 3.5734e-06\n",
      "Epoch 284/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5185e-05 - val_loss: 3.5399e-06\n",
      "Epoch 285/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5127e-05 - val_loss: 3.6071e-06\n",
      "Epoch 286/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5103e-05 - val_loss: 3.5659e-06\n",
      "Epoch 287/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5120e-05 - val_loss: 3.6514e-06\n",
      "Epoch 288/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5117e-05 - val_loss: 3.5404e-06\n",
      "Epoch 289/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5086e-05 - val_loss: 3.8256e-06\n",
      "Epoch 290/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5160e-05 - val_loss: 3.6060e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5174e-05 - val_loss: 3.6768e-06\n",
      "Epoch 292/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5120e-05 - val_loss: 3.6652e-06\n",
      "Epoch 293/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5168e-05 - val_loss: 3.6685e-06\n",
      "Epoch 294/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5101e-05 - val_loss: 3.8503e-06\n",
      "Epoch 295/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5124e-05 - val_loss: 3.7334e-06\n",
      "Epoch 296/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5174e-05 - val_loss: 3.7218e-06\n",
      "Epoch 297/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5143e-05 - val_loss: 3.7058e-06\n",
      "Epoch 298/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5150e-05 - val_loss: 3.6428e-06\n",
      "Epoch 299/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5120e-05 - val_loss: 3.7418e-06\n",
      "Epoch 300/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5141e-05 - val_loss: 3.8163e-06\n",
      "Epoch 301/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5100e-05 - val_loss: 3.6297e-06\n",
      "Epoch 302/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5118e-05 - val_loss: 3.5971e-06\n",
      "Epoch 303/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5127e-05 - val_loss: 3.6164e-06\n",
      "Epoch 304/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5141e-05 - val_loss: 3.6984e-06\n",
      "Epoch 305/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5101e-05 - val_loss: 3.6963e-06\n",
      "Epoch 306/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5127e-05 - val_loss: 3.5954e-06\n",
      "Epoch 307/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5184e-05 - val_loss: 3.6848e-06\n",
      "Epoch 308/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5128e-05 - val_loss: 3.7326e-06\n",
      "Epoch 309/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5156e-05 - val_loss: 3.7950e-06\n",
      "Epoch 310/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5124e-05 - val_loss: 3.7380e-06\n",
      "Epoch 311/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5125e-05 - val_loss: 3.6958e-06\n",
      "Epoch 312/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5173e-05 - val_loss: 3.5400e-06\n",
      "Epoch 313/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5441e-05 - val_loss: 3.5914e-06\n",
      "Epoch 314/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5299e-05 - val_loss: 3.5951e-06\n",
      "Epoch 315/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5224e-05 - val_loss: 3.5725e-06\n",
      "Epoch 316/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5211e-05 - val_loss: 3.6183e-06\n",
      "Epoch 317/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5197e-05 - val_loss: 3.8218e-06\n",
      "Epoch 318/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5153e-05 - val_loss: 3.6014e-06\n",
      "Epoch 319/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5117e-05 - val_loss: 3.6134e-06\n",
      "Epoch 320/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5171e-05 - val_loss: 3.7200e-06\n",
      "Epoch 321/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5158e-05 - val_loss: 3.8444e-06\n",
      "Epoch 322/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5179e-05 - val_loss: 3.7183e-06\n",
      "Epoch 323/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5155e-05 - val_loss: 3.6357e-06\n",
      "Epoch 324/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5199e-05 - val_loss: 3.8383e-06\n",
      "Epoch 325/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5223e-05 - val_loss: 3.8305e-06\n",
      "Epoch 326/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5234e-05 - val_loss: 3.8553e-06\n",
      "Epoch 327/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5212e-05 - val_loss: 3.5587e-06\n",
      "Epoch 328/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5134e-05 - val_loss: 3.5472e-06\n",
      "Epoch 329/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5087e-05 - val_loss: 3.9661e-06\n",
      "Epoch 330/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5231e-05 - val_loss: 3.6308e-06\n",
      "Epoch 331/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5096e-05 - val_loss: 3.8197e-06\n",
      "Epoch 332/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5179e-05 - val_loss: 3.8597e-06\n",
      "Epoch 333/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5150e-05 - val_loss: 3.7020e-06\n",
      "Epoch 334/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5215e-05 - val_loss: 3.8778e-06\n",
      "Epoch 335/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5173e-05 - val_loss: 3.6712e-06\n",
      "Epoch 336/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5105e-05 - val_loss: 3.8737e-06\n",
      "Epoch 337/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5169e-05 - val_loss: 3.7545e-06\n",
      "Epoch 338/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5176e-05 - val_loss: 3.7321e-06\n",
      "Epoch 339/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5195e-05 - val_loss: 3.9215e-06\n",
      "Epoch 340/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5164e-05 - val_loss: 3.8071e-06\n",
      "Epoch 341/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5168e-05 - val_loss: 3.6909e-06\n",
      "Epoch 342/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5095e-05 - val_loss: 3.6977e-06\n",
      "Epoch 343/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5207e-05 - val_loss: 3.7145e-06\n",
      "Epoch 344/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5308e-05 - val_loss: 3.8642e-06\n",
      "Epoch 345/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5283e-05 - val_loss: 3.5884e-06\n",
      "Epoch 346/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5350e-05 - val_loss: 3.5500e-06\n",
      "Epoch 347/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5343e-05 - val_loss: 3.5841e-06\n",
      "Epoch 348/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5404e-05 - val_loss: 3.5398e-06\n",
      "Epoch 349/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5158e-05 - val_loss: 3.7937e-06\n",
      "Epoch 350/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5094e-05 - val_loss: 3.5877e-06\n",
      "Epoch 351/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5105e-05 - val_loss: 3.7331e-06\n",
      "Epoch 352/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5117e-05 - val_loss: 3.5556e-06\n",
      "Epoch 353/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5090e-05 - val_loss: 3.5519e-06\n",
      "Epoch 354/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5156e-05 - val_loss: 3.8783e-06\n",
      "Epoch 355/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5219e-05 - val_loss: 3.6084e-06\n",
      "Epoch 356/600\n",
      "4288/4288 [==============================] - 0s 36us/step - loss: 1.5108e-05 - val_loss: 3.7365e-06\n",
      "Epoch 357/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5167e-05 - val_loss: 3.6005e-06\n",
      "Epoch 358/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5165e-05 - val_loss: 3.6118e-06\n",
      "Epoch 359/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5147e-05 - val_loss: 3.7724e-06\n",
      "Epoch 360/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5109e-05 - val_loss: 3.5821e-06\n",
      "Epoch 361/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5114e-05 - val_loss: 3.6667e-06\n",
      "Epoch 362/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5198e-05 - val_loss: 3.6311e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5274e-05 - val_loss: 3.5930e-06\n",
      "Epoch 364/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5240e-05 - val_loss: 3.7266e-06\n",
      "Epoch 365/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5190e-05 - val_loss: 3.7869e-06\n",
      "Epoch 366/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5095e-05 - val_loss: 3.6728e-06\n",
      "Epoch 367/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5143e-05 - val_loss: 3.5643e-06\n",
      "Epoch 368/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5144e-05 - val_loss: 3.6486e-06\n",
      "Epoch 369/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5147e-05 - val_loss: 3.7825e-06\n",
      "Epoch 370/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5146e-05 - val_loss: 3.6971e-06\n",
      "Epoch 371/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5127e-05 - val_loss: 3.6281e-06\n",
      "Epoch 372/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5183e-05 - val_loss: 3.5828e-06\n",
      "Epoch 373/600\n",
      "4288/4288 [==============================] - 0s 31us/step - loss: 1.5163e-05 - val_loss: 3.6095e-06\n",
      "Epoch 374/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5179e-05 - val_loss: 3.6080e-06\n",
      "Epoch 375/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5110e-05 - val_loss: 3.5393e-06\n",
      "Epoch 376/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5238e-05 - val_loss: 3.5958e-06\n",
      "Epoch 377/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5135e-05 - val_loss: 3.6815e-06\n",
      "Epoch 378/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5176e-05 - val_loss: 4.1200e-06\n",
      "Epoch 379/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5284e-05 - val_loss: 3.9268e-06\n",
      "Epoch 380/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5315e-05 - val_loss: 3.6931e-06\n",
      "Epoch 381/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5227e-05 - val_loss: 4.1156e-06\n",
      "Epoch 382/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5213e-05 - val_loss: 3.8982e-06\n",
      "Epoch 383/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5183e-05 - val_loss: 3.5946e-06\n",
      "Epoch 384/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5115e-05 - val_loss: 3.6828e-06\n",
      "Epoch 385/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5136e-05 - val_loss: 3.6605e-06\n",
      "Epoch 386/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5132e-05 - val_loss: 3.5845e-06\n",
      "Epoch 387/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5141e-05 - val_loss: 3.5429e-06\n",
      "Epoch 388/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5265e-05 - val_loss: 3.5524e-06\n",
      "Epoch 389/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5207e-05 - val_loss: 3.5843e-06\n",
      "Epoch 390/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5145e-05 - val_loss: 3.7645e-06\n",
      "Epoch 391/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5187e-05 - val_loss: 3.9027e-06\n",
      "Epoch 392/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5178e-05 - val_loss: 3.6999e-06\n",
      "Epoch 393/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5138e-05 - val_loss: 3.6922e-06\n",
      "Epoch 394/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5123e-05 - val_loss: 3.7437e-06\n",
      "Epoch 395/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5111e-05 - val_loss: 3.7918e-06\n",
      "Epoch 396/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5130e-05 - val_loss: 3.6617e-06\n",
      "Epoch 397/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5126e-05 - val_loss: 3.6927e-06\n",
      "Epoch 398/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5170e-05 - val_loss: 3.7131e-06\n",
      "Epoch 399/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5248e-05 - val_loss: 3.9853e-06\n",
      "Epoch 400/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5183e-05 - val_loss: 3.8822e-06\n",
      "Epoch 401/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5202e-05 - val_loss: 4.1058e-06\n",
      "Epoch 402/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5260e-05 - val_loss: 3.7315e-06\n",
      "Epoch 403/600\n",
      "4288/4288 [==============================] - 0s 40us/step - loss: 1.5114e-05 - val_loss: 3.5497e-06\n",
      "Epoch 404/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5288e-05 - val_loss: 3.5556e-06\n",
      "Epoch 405/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5160e-05 - val_loss: 4.0199e-06\n",
      "Epoch 406/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5158e-05 - val_loss: 3.6179e-06\n",
      "Epoch 407/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5188e-05 - val_loss: 3.9568e-06\n",
      "Epoch 408/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5148e-05 - val_loss: 3.6465e-06\n",
      "Epoch 409/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5141e-05 - val_loss: 3.9064e-06\n",
      "Epoch 410/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5213e-05 - val_loss: 3.6435e-06\n",
      "Epoch 411/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5139e-05 - val_loss: 4.1030e-06\n",
      "Epoch 412/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5203e-05 - val_loss: 4.1144e-06\n",
      "Epoch 413/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5227e-05 - val_loss: 3.6710e-06\n",
      "Epoch 414/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5115e-05 - val_loss: 3.6508e-06\n",
      "Epoch 415/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5169e-05 - val_loss: 4.3240e-06\n",
      "Epoch 416/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5242e-05 - val_loss: 3.7264e-06\n",
      "Epoch 417/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5143e-05 - val_loss: 3.7625e-06\n",
      "Epoch 418/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5137e-05 - val_loss: 3.6775e-06\n",
      "Epoch 419/600\n",
      "4288/4288 [==============================] - 0s 32us/step - loss: 1.5145e-05 - val_loss: 3.5463e-06\n",
      "Epoch 420/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5180e-05 - val_loss: 3.6669e-06\n",
      "Epoch 421/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5240e-05 - val_loss: 3.5397e-06\n",
      "Epoch 422/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5326e-05 - val_loss: 3.6433e-06\n",
      "Epoch 423/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5253e-05 - val_loss: 3.7189e-06\n",
      "Epoch 424/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5167e-05 - val_loss: 3.8948e-06\n",
      "Epoch 425/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5215e-05 - val_loss: 3.6156e-06\n",
      "Epoch 426/600\n",
      "4288/4288 [==============================] - 0s 31us/step - loss: 1.5109e-05 - val_loss: 3.6215e-06\n",
      "Epoch 427/600\n",
      "4288/4288 [==============================] - 0s 31us/step - loss: 1.5211e-05 - val_loss: 3.6179e-06\n",
      "Epoch 428/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5282e-05 - val_loss: 3.7457e-06\n",
      "Epoch 429/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5146e-05 - val_loss: 3.5900e-06\n",
      "Epoch 430/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5194e-05 - val_loss: 3.9926e-06\n",
      "Epoch 431/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5140e-05 - val_loss: 3.6623e-06\n",
      "Epoch 432/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5155e-05 - val_loss: 3.5732e-06\n",
      "Epoch 433/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5139e-05 - val_loss: 3.6210e-06\n",
      "Epoch 434/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5307e-05 - val_loss: 3.7197e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5110e-05 - val_loss: 3.6244e-06\n",
      "Epoch 436/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5095e-05 - val_loss: 3.5420e-06\n",
      "Epoch 437/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5197e-05 - val_loss: 3.9868e-06\n",
      "Epoch 438/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5265e-05 - val_loss: 4.1968e-06\n",
      "Epoch 439/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5286e-05 - val_loss: 3.6634e-06\n",
      "Epoch 440/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5167e-05 - val_loss: 3.5827e-06\n",
      "Epoch 441/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5392e-05 - val_loss: 3.5398e-06\n",
      "Epoch 442/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5246e-05 - val_loss: 4.2647e-06\n",
      "Epoch 443/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5266e-05 - val_loss: 3.9661e-06\n",
      "Epoch 444/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5226e-05 - val_loss: 3.5416e-06\n",
      "Epoch 445/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5252e-05 - val_loss: 3.5482e-06\n",
      "Epoch 446/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5193e-05 - val_loss: 3.7871e-06\n",
      "Epoch 447/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5186e-05 - val_loss: 3.9559e-06\n",
      "Epoch 448/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5207e-05 - val_loss: 3.6031e-06\n",
      "Epoch 449/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5194e-05 - val_loss: 3.5420e-06\n",
      "Epoch 450/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5157e-05 - val_loss: 3.9629e-06\n",
      "Epoch 451/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5128e-05 - val_loss: 3.6040e-06\n",
      "Epoch 452/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5128e-05 - val_loss: 3.5838e-06\n",
      "Epoch 453/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5248e-05 - val_loss: 3.7368e-06\n",
      "Epoch 454/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5148e-05 - val_loss: 3.8465e-06\n",
      "Epoch 455/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5147e-05 - val_loss: 3.5874e-06\n",
      "Epoch 456/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5123e-05 - val_loss: 3.6652e-06\n",
      "Epoch 457/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5133e-05 - val_loss: 3.6725e-06\n",
      "Epoch 458/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5094e-05 - val_loss: 3.6499e-06\n",
      "Epoch 459/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5151e-05 - val_loss: 3.7936e-06\n",
      "Epoch 460/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5154e-05 - val_loss: 3.6257e-06\n",
      "Epoch 461/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5100e-05 - val_loss: 3.5717e-06\n",
      "Epoch 462/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5201e-05 - val_loss: 3.6144e-06\n",
      "Epoch 463/600\n",
      "4288/4288 [==============================] - 0s 18us/step - loss: 1.5126e-05 - val_loss: 3.8130e-06\n",
      "Epoch 464/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5181e-05 - val_loss: 3.8425e-06\n",
      "Epoch 465/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5119e-05 - val_loss: 3.5674e-06\n",
      "Epoch 466/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5131e-05 - val_loss: 3.7360e-06\n",
      "Epoch 467/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5225e-05 - val_loss: 4.2001e-06\n",
      "Epoch 468/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5222e-05 - val_loss: 3.7708e-06\n",
      "Epoch 469/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5180e-05 - val_loss: 3.7085e-06\n",
      "Epoch 470/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5140e-05 - val_loss: 3.7518e-06\n",
      "Epoch 471/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5254e-05 - val_loss: 3.5835e-06\n",
      "Epoch 472/600\n",
      "4288/4288 [==============================] - 0s 30us/step - loss: 1.5262e-05 - val_loss: 3.5461e-06\n",
      "Epoch 473/600\n",
      "4288/4288 [==============================] - 0s 31us/step - loss: 1.5205e-05 - val_loss: 3.6681e-06\n",
      "Epoch 474/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5209e-05 - val_loss: 3.7071e-06\n",
      "Epoch 475/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5145e-05 - val_loss: 3.6295e-06\n",
      "Epoch 476/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5205e-05 - val_loss: 3.7496e-06\n",
      "Epoch 477/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5144e-05 - val_loss: 3.7610e-06\n",
      "Epoch 478/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5184e-05 - val_loss: 3.6938e-06\n",
      "Epoch 479/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5156e-05 - val_loss: 3.6295e-06\n",
      "Epoch 480/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5142e-05 - val_loss: 3.6312e-06\n",
      "Epoch 481/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5184e-05 - val_loss: 3.7028e-06\n",
      "Epoch 482/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5203e-05 - val_loss: 3.5711e-06\n",
      "Epoch 483/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5093e-05 - val_loss: 3.7195e-06\n",
      "Epoch 484/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5140e-05 - val_loss: 3.6549e-06\n",
      "Epoch 485/600\n",
      "4288/4288 [==============================] - 0s 36us/step - loss: 1.5141e-05 - val_loss: 3.6612e-06\n",
      "Epoch 486/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5167e-05 - val_loss: 3.6104e-06\n",
      "Epoch 487/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5103e-05 - val_loss: 3.7081e-06\n",
      "Epoch 488/600\n",
      "4288/4288 [==============================] - 0s 27us/step - loss: 1.5132e-05 - val_loss: 3.6307e-06\n",
      "Epoch 489/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5132e-05 - val_loss: 3.7678e-06\n",
      "Epoch 490/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5132e-05 - val_loss: 3.5508e-06\n",
      "Epoch 491/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5195e-05 - val_loss: 3.7896e-06\n",
      "Epoch 492/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5199e-05 - val_loss: 3.7611e-06\n",
      "Epoch 493/600\n",
      "4288/4288 [==============================] - 0s 31us/step - loss: 1.5313e-05 - val_loss: 3.6276e-06\n",
      "Epoch 494/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5157e-05 - val_loss: 3.5991e-06\n",
      "Epoch 495/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5119e-05 - val_loss: 3.9075e-06\n",
      "Epoch 496/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5131e-05 - val_loss: 3.6785e-06\n",
      "Epoch 497/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5192e-05 - val_loss: 3.5922e-06\n",
      "Epoch 498/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5129e-05 - val_loss: 3.6629e-06\n",
      "Epoch 499/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5180e-05 - val_loss: 3.7923e-06\n",
      "Epoch 500/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5220e-05 - val_loss: 3.7143e-06\n",
      "Epoch 501/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5138e-05 - val_loss: 3.5577e-06\n",
      "Epoch 502/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5159e-05 - val_loss: 3.7275e-06\n",
      "Epoch 503/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5181e-05 - val_loss: 3.8088e-06\n",
      "Epoch 504/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5191e-05 - val_loss: 3.6949e-06\n",
      "Epoch 505/600\n",
      "4288/4288 [==============================] - 0s 29us/step - loss: 1.5208e-05 - val_loss: 3.6150e-06\n",
      "Epoch 506/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5170e-05 - val_loss: 3.5547e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 507/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5140e-05 - val_loss: 3.5448e-06\n",
      "Epoch 508/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5186e-05 - val_loss: 3.6732e-06\n",
      "Epoch 509/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5166e-05 - val_loss: 3.6520e-06\n",
      "Epoch 510/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5135e-05 - val_loss: 3.7196e-06\n",
      "Epoch 511/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5159e-05 - val_loss: 3.5737e-06\n",
      "Epoch 512/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5138e-05 - val_loss: 3.6028e-06\n",
      "Epoch 513/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5180e-05 - val_loss: 3.5389e-06\n",
      "Epoch 514/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5148e-05 - val_loss: 3.7306e-06\n",
      "Epoch 515/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5187e-05 - val_loss: 3.6811e-06\n",
      "Epoch 516/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5133e-05 - val_loss: 3.6682e-06\n",
      "Epoch 517/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5161e-05 - val_loss: 3.5471e-06\n",
      "Epoch 518/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5152e-05 - val_loss: 3.6182e-06\n",
      "Epoch 519/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5139e-05 - val_loss: 3.8038e-06\n",
      "Epoch 520/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5163e-05 - val_loss: 3.8811e-06\n",
      "Epoch 521/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5223e-05 - val_loss: 3.5514e-06\n",
      "Epoch 522/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5229e-05 - val_loss: 3.5460e-06\n",
      "Epoch 523/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5156e-05 - val_loss: 3.7339e-06\n",
      "Epoch 524/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5069e-05 - val_loss: 3.6573e-06\n",
      "Epoch 525/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5126e-05 - val_loss: 3.8963e-06\n",
      "Epoch 526/600\n",
      "4288/4288 [==============================] - 0s 18us/step - loss: 1.5137e-05 - val_loss: 3.7124e-06\n",
      "Epoch 527/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5148e-05 - val_loss: 3.6184e-06\n",
      "Epoch 528/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5081e-05 - val_loss: 3.7578e-06\n",
      "Epoch 529/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5141e-05 - val_loss: 3.8021e-06\n",
      "Epoch 530/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5243e-05 - val_loss: 3.7003e-06\n",
      "Epoch 531/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5151e-05 - val_loss: 3.8366e-06\n",
      "Epoch 532/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5193e-05 - val_loss: 3.6332e-06\n",
      "Epoch 533/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5158e-05 - val_loss: 3.5390e-06\n",
      "Epoch 534/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5195e-05 - val_loss: 3.7766e-06\n",
      "Epoch 535/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5161e-05 - val_loss: 3.7633e-06\n",
      "Epoch 536/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5173e-05 - val_loss: 3.9315e-06\n",
      "Epoch 537/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5119e-05 - val_loss: 3.5552e-06\n",
      "Epoch 538/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5175e-05 - val_loss: 3.5386e-06\n",
      "Epoch 539/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5321e-05 - val_loss: 3.7210e-06\n",
      "Epoch 540/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5293e-05 - val_loss: 4.1451e-06\n",
      "Epoch 541/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5207e-05 - val_loss: 3.8974e-06\n",
      "Epoch 542/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5234e-05 - val_loss: 3.5918e-06\n",
      "Epoch 543/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5153e-05 - val_loss: 3.5996e-06\n",
      "Epoch 544/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5097e-05 - val_loss: 3.6582e-06\n",
      "Epoch 545/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5174e-05 - val_loss: 3.7931e-06\n",
      "Epoch 546/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5150e-05 - val_loss: 3.6302e-06\n",
      "Epoch 547/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5111e-05 - val_loss: 3.8476e-06\n",
      "Epoch 548/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5134e-05 - val_loss: 3.6047e-06\n",
      "Epoch 549/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5104e-05 - val_loss: 3.7429e-06\n",
      "Epoch 550/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5229e-05 - val_loss: 4.1726e-06\n",
      "Epoch 551/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5268e-05 - val_loss: 3.7957e-06\n",
      "Epoch 552/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5216e-05 - val_loss: 3.5577e-06\n",
      "Epoch 553/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5172e-05 - val_loss: 3.7674e-06\n",
      "Epoch 554/600\n",
      "4288/4288 [==============================] - 0s 20us/step - loss: 1.5102e-05 - val_loss: 3.6282e-06\n",
      "Epoch 555/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5119e-05 - val_loss: 3.6572e-06\n",
      "Epoch 556/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5146e-05 - val_loss: 3.5890e-06\n",
      "Epoch 557/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5189e-05 - val_loss: 3.7237e-06\n",
      "Epoch 558/600\n",
      "4288/4288 [==============================] - 0s 19us/step - loss: 1.5165e-05 - val_loss: 3.7687e-06\n",
      "Epoch 559/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5136e-05 - val_loss: 3.7317e-06\n",
      "Epoch 560/600\n",
      "4288/4288 [==============================] - 0s 31us/step - loss: 1.5125e-05 - val_loss: 3.5544e-06\n",
      "Epoch 561/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5149e-05 - val_loss: 3.7968e-06\n",
      "Epoch 562/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5200e-05 - val_loss: 3.5599e-06\n",
      "Epoch 563/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5148e-05 - val_loss: 3.7090e-06\n",
      "Epoch 564/600\n",
      "4288/4288 [==============================] - 0s 41us/step - loss: 1.5192e-05 - val_loss: 3.7854e-06\n",
      "Epoch 565/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5189e-05 - val_loss: 3.8187e-06\n",
      "Epoch 566/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5240e-05 - val_loss: 3.5422e-06\n",
      "Epoch 567/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5232e-05 - val_loss: 3.5654e-06\n",
      "Epoch 568/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5123e-05 - val_loss: 3.7422e-06\n",
      "Epoch 569/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5124e-05 - val_loss: 3.7210e-06\n",
      "Epoch 570/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5161e-05 - val_loss: 3.5504e-06\n",
      "Epoch 571/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5187e-05 - val_loss: 3.5392e-06\n",
      "Epoch 572/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5284e-05 - val_loss: 3.7487e-06\n",
      "Epoch 573/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5143e-05 - val_loss: 3.5563e-06\n",
      "Epoch 574/600\n",
      "4288/4288 [==============================] - 0s 26us/step - loss: 1.5160e-05 - val_loss: 3.6413e-06\n",
      "Epoch 575/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5105e-05 - val_loss: 3.8196e-06\n",
      "Epoch 576/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5194e-05 - val_loss: 3.7414e-06\n",
      "Epoch 577/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5101e-05 - val_loss: 3.6906e-06\n",
      "Epoch 578/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5109e-05 - val_loss: 3.7898e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 579/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5198e-05 - val_loss: 3.5725e-06\n",
      "Epoch 580/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5147e-05 - val_loss: 3.5578e-06\n",
      "Epoch 581/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5143e-05 - val_loss: 3.7063e-06\n",
      "Epoch 582/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5160e-05 - val_loss: 3.6708e-06\n",
      "Epoch 583/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5217e-05 - val_loss: 3.8501e-06\n",
      "Epoch 584/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5135e-05 - val_loss: 3.6840e-06\n",
      "Epoch 585/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5144e-05 - val_loss: 3.5847e-06\n",
      "Epoch 586/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5170e-05 - val_loss: 3.9394e-06\n",
      "Epoch 587/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5251e-05 - val_loss: 3.9509e-06\n",
      "Epoch 588/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5292e-05 - val_loss: 3.9659e-06\n",
      "Epoch 589/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5225e-05 - val_loss: 3.5398e-06\n",
      "Epoch 590/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5194e-05 - val_loss: 3.6589e-06\n",
      "Epoch 591/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5153e-05 - val_loss: 3.6208e-06\n",
      "Epoch 592/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5119e-05 - val_loss: 3.7110e-06\n",
      "Epoch 593/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5119e-05 - val_loss: 3.5543e-06\n",
      "Epoch 594/600\n",
      "4288/4288 [==============================] - 0s 22us/step - loss: 1.5135e-05 - val_loss: 3.7398e-06\n",
      "Epoch 595/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5147e-05 - val_loss: 3.8809e-06\n",
      "Epoch 596/600\n",
      "4288/4288 [==============================] - 0s 21us/step - loss: 1.5155e-05 - val_loss: 3.6885e-06\n",
      "Epoch 597/600\n",
      "4288/4288 [==============================] - 0s 24us/step - loss: 1.5085e-05 - val_loss: 3.6051e-06\n",
      "Epoch 598/600\n",
      "4288/4288 [==============================] - 0s 23us/step - loss: 1.5171e-05 - val_loss: 3.6421e-06\n",
      "Epoch 599/600\n",
      "4288/4288 [==============================] - 0s 28us/step - loss: 1.5126e-05 - val_loss: 3.8070e-06\n",
      "Epoch 600/600\n",
      "4288/4288 [==============================] - 0s 25us/step - loss: 1.5153e-05 - val_loss: 3.7857e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Create neural network model ---\\n\")\n",
    "\n",
    "# 1D CNN neural network\n",
    "model_m = Sequential()\n",
    "model_m.add(Reshape((TIME_PERIODS, num_features), input_shape=(input_shape,)))  # 0\n",
    "model_m.add(Conv1D(filter_depths[0], filter_height, activation='tanh', input_shape=(TIME_PERIODS, num_features)))  # 1\n",
    "model_m.add(Conv1D(filter_depths[1], filter_height, activation='tanh'))  # 2\n",
    "# model_m.add(MaxPooling1D(3))\n",
    "model_m.add(AveragePooling1D(N_FEATURES))  # 3\n",
    "model_m.add(Conv1D(filter_depths[2], filter_height, activation='tanh'))  # 4\n",
    "model_m.add(Conv1D(filter_depths[3], filter_height, activation='tanh'))  # 5\n",
    "model_m.add(GlobalAveragePooling1D())  # 6\n",
    "model_m.add(Dropout(drop_out))  # 7\n",
    "model_m.add(Dense(1))  # 8\n",
    "print(model_m.summary())\n",
    "\n",
    "model_m.compile(optimizer=optimizers.Adam(lr=1e-04), loss='mean_squared_error')\n",
    "\n",
    "print(\"\\n--- Fit the model ---\\n\")\n",
    "\n",
    "# The EarlyStopping callback monitors training accuracy:\n",
    "# if it fails to improve for two consecutive epochs,\n",
    "# training stops early\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=root_folder + 'models_regression/best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "        monitor='val_loss', save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='acc', patience=3)\n",
    "]\n",
    "\n",
    "# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
    "history = model_m.fit(x_train,\n",
    "                      y_train,\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      epochs=EPOCHS,\n",
    "                      callbacks=callbacks_list,\n",
    "                      validation_split=0.2,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x115edbb90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEWCAYAAAApTuNLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XucVfP++PHX23RDiCRRFOXSnUbFEcmlEoUTSkdyORxETkIdvgdx/CTkHoUkUqkkhXCKynFpStJFmmrSRJqmi+7N5f374/PZ7T179p7Zc9nNnub9fDz2Y6/1WZ/1WZ/P2muv91qfvfZaoqoYY4wxZe2gsq6AMcYYAxaQjDHGJAgLSMYYYxKCBSRjjDEJwQKSMcaYhGAByRhjTEKwgGRMAhOR+iKiIlIphrx9RGTu/qiXMfFgAcmYUiIiaSKyV0SODkv/wQeV+mVTs6IFNmPKigUkY0rXaqBnYEREmgGHlF11jCk/LCAZU7rGAL1Dxm8A3g7NICJHiMjbIpIhImtE5CEROchPSxKRp0Vko4isArpEmPcNEfldRNaJyOMiklSSCotIVRF5TkR+86/nRKSqn3a0iEwTkS0isklE5oTU9QFfh20islxELixJPYyxgGRM6foWOFxETveBogfwTlieF4EjgJOA83EB7EY/7e/AZcAZQDLQPWzet4BsoKHPcwlwSwnr/CDQFmgJtABaAw/5afcC6UAtoDbwL0BF5FSgL3CWqh4GdATSSlgPU8FZQDKm9AXOki4GlgHrAhNCgtQgVd2mqmnAM8D1Pss1wHOqulZVNwH/L2Te2sClwD2qukNVNwDDfHkl0QsYrKobVDUDeDSkPllAHeBEVc1S1TnqboCZA1QFGotIZVVNU9WVJayHqeAsIBlT+sYA1wF9COuuA44GKgNrQtLWAMf74eOAtWHTAk708/7uu9C2AK8Bx5SwvsdFqM9xfngokAp8JiKrRGQggKqmAvcAjwAbRGSciByHMSVgAcmYUqaqa3AXN1wKTA6bvBF31nFiSNoJBM+ifgfqhU0LWAvsAY5W1Rr+dbiqNilhlX+LUJ/ffFu2qeq9qnoS0BXoH/itSFXHquq5fl4FhpSwHqaCs4BkTHzcDHRQ1R2hiaqaA0wA/iMih4nIiUB/gr8zTQDuFpG6InIkMDBk3t+Bz4BnRORwETlIRE4WkfOLUK+qIlIt5HUQ8B7wkIjU8pes/ztQHxG5TEQaiogAW3FddbkicqqIdPAXP+wGdgG5RVxHxuRhAcmYOFDVlaqaEmXyXcAOYBUwFxgLvOmnjQRmAD8CC8h/htUbqAIsBTYDE3G/8cRqOy54BF4dgMeBFGAR8JNf7uM+fyPgCz/fN8ArqjoL9/vRk7gzvvW4bsNBRaiHMfmIPaDPGGNMIrAzJGOMMQnBApIxxpiEENeAJCKd/D+4UwOXi4ZNryoi4/3070Lv9SUig3z6chHpWFiZItLAl5Hqy6zi088TkQUiki0i3cOWf4KIfCYiy0RkaVnea8wYYyq6uAUk/wfAl4HOQGOgp4g0Dst2M7BZVRvi/uA3xM/bGPdnvyZAJ+AVf0uVgsocAgzzZW32ZQP8ivs/yNgI1XwbGKqqp+P+nb6hpO02xhhTPPG8829rIFVVVwGIyDigG+7qoIBuuD/Wgbta6CV/eWk3YJyq7gFWi0iqL49IZYrIMtzVQtf5PKN9ucP9P+ERkTyXpPpAVklVPwdQ1e2FNejoo4/W+vXrx9h8Y4wxAPPnz9+oqrUKyxfPgHQ8ef9xng60iZZHVbNFZCtQ06d/GzZv4J/skcqsCWxR1ewI+aM5BdgiIpOBBrhLWwf6/4lEVL9+fVJSol3Ja4wxJhIRWVN4rop9UUMloB0wADgLd6PLPuGZRORWEUkRkZSMjIz9W0NjjKlA4hmQ1pH3Fih1CbnJZHge/+CwI4DMAuaNlp4J1Ah5+FikZYVLBxaq6ip/ZjUFODM8k6qOUNVkVU2uVavQM05jjDHFFM+ANA9o5K9+q4K7SGFqWJ6puOfFgLvN/kx/J+GpQA9/FV4D3L/Fv49Wpp9nFsFb9d8AfBhD/WqISCDKdCDv71vGGGP2o7gFJH/W0Rd3G5RlwARVXSIig0Wkq8/2BlDTX7TQH3/fLlVdgrun11LgU+BOVc2JVqYv6wHcjR9Tcb8pvQEgImeJSDpwNfCaiCzxy8jBddf9V0R+AgR32xZjjDFlwG4dVATJyclqFzUYY0zRiMh8VU0uLF9Fvqhhv1qxAv78s6xrsX8sXAg5Ua9VNMaYyCwg7QepqXDKKfDmm4XnLcyMGdCkCSxfXvKy4mHBAjjjDBhiT8ZJCEuXwujRJS8nOxty7eESJs4sIO0HDRvCOefA8OFFm2/UKPjqq7xpd93ldjLPPFN69fvtN7fTitR7u2EDbNsWe1mLFrn3efOi5/nyS9i0qUhVjEoV5s51O8zC8kU7a5s/H3r0gKysYN4DpSf74ouhTx/IzCx+GcuWQdWq0LNnqVVrv5o0Cdq1s4BaLqiqvWJ8tWrVSotr2DC3m/vxR9V581Rzc1U/+UR1/fr8eTdtUh0xIrBbVK1XT3X+fNU9e1QPPTSY/tprqv/3f6otWqiuWJG3jIULVadNc8OrVqkuWeKGN25UzcrKm7dhQ1fevHl503NzVY89VrVmTbdsVdX0dNWuXVV//111+nTVnBzVb7917VJVve8+V1b37nnLmjNHtWVL1XHj3PTWrVVff131lFOCZRcmN1d19Wo3nJ2tOnas6pAhrrwHHnDTs7Mjz/vvf6tWr666a1ewrEDeZs1cGV9/7dLbtlU99VTVzZsLrs/o0e4zuO021fPPzztt+3ZXVqj//U/1r39VfeONvOmrVrn8qqrr1qn++afqhg3uvaSqVnVtGz++ePM/8khwe4Po+X74QXX37ujThwxRvewy1b173XhWlmtrNL//rvrqq9E/T1W3zR91lOqnn7p1PXmy6rZtruwbb3R1mj8/WPdp0/J/JrHYuNGVW5gdO1Q7dlT95puiLyMWAweqXnSRamZm/uVG2o9EMmOG6po10adPnKg6e3bx6xgNkKIx7GPLfCdfnl4lCUjffJP3ix14nXmm6qJFqjNnqrZpo1qrlmqTJpHzBl53350/7Z573A7s2WdVjzsumJ6aqlq5sht++mkX0JKSVF94wX05P/44mLdGDdV331X96SfVzz5zgSYw7d133TwDBrjx0GWA6uGHq27d6nbmoHraaap//BFs/8UXu/RDDslf908+UV22zAWVtm1V77rL7Wx27sy7Q/r3v13+MWNU/9//y1/OCSe49y5dXJD7+WfVd95RvfrqYJ7hw10gq1ZN9Zhj3E40EJCeeUZ18eJg3q5d3Y78o49UJ0xQfe891fbt3Rf69dfzL3/RIrdOf/vNjb/4otsBXHyxW5e1agXzNmvmds7r1gXXV3a26pFHBvOcdZZr93ffufljlZsbDA7HHuvKatnSlaPqlvPFF6qXX+7W48MPu+3gww9VFyxw627RIndgFKjLiSeqirjPZPt21cceU92yxZU3c6bL07Zt8GAnJ8fVYdIk145AOf36ueU/+aQbnzXL7VAD9e7UKe86HT7c7YBfekn10UfdKznZHWD9/e/BfLfe6t579gxutwcfnP8zqllTdeRI1ZQU1+ZTT3XtDFi+3B10/f67ap8+bnlVq7ptZexY1aVL3ee2ZIkbDvXEE24Zbdq4bf+HH9yyNm922+yaNcF1lpPj1mNg+375ZdW//S0Y+JYsUT3jDNX//tctJycnbzsCB6C7drmDuho1XL337lXNyHDTfvrJHSiee64L0Onpbt4mTdx2t22bK3vDBreeQ/cFBQWt4rCAFIdXSQLSnj3BD7t27fxflEiv9u3dFyjSDnzRouB4pUqxlRf+qlHDfWkbNlQ96aTIeapUib28Sy91O63AThBU//EPFyBiLat+fd23w65Tp/D8N9/sgu4xxxRvHYQGAHB1FyleWeCCfXHnjfRq1y44PGKEOxto2dKNn3WWW19du6r+85+qU6e6nWKHDm56YOfepEneM+vA66CDYqvD998Hz2w//VT1ppuC0zp1cmfwgfGTTlK9/XYX8MPLad7cvTdoEDxICmyHI0e6g6qibLsiRdv2Q+sZ+hknJ7uDte7di/75XH21C8SPPx49T/i6P/nkvOMXXhgcvuUW1QcfVD3ssMKX3ayZO6ANjLdp4z77ypXdmVR4/urVY2tT1apuXb32mmrv3m4fcdBBrvejuCwgxeFVkoCk6rpqunVzR5nff++6yP72N3d03KuXO1oNdLHcequbJzvbHW09+qg7lb777uAR5Ztvqj70kDvyadzYzXfOOapz56pOmeJO8Q85xE3bvt11F/3f/7n5WrZ0XX29e7uuqsce03071CuvVH3+ebfjWbTI5QndYPv0CX6527d35fXoofu+9GvWuC660J3Occeprl0b3FF9+607KwqcaXXsqDp4sDsSHDEi+s5y7FjXjp498x6hrlvnxrOzXdtvvz24477uOnfm+Mcfqq1auZ3ZQw8Fy7z6atU77wyO33uv6/4JjLdq5XY4zZu7zwrcGeHixa7b7p//jC0gnneeO4tNS3NHv+ee63ZGH3wQDNannup2BK+/rlq3bnDdhJ5dFeV1xBEuYG/dGlwfzZq5z2vDhujzhe6cA2d9kc44Ap/n0KHBHV6knemgQe5zuv76YFq3bq4uoeuuVatg8AN39B8o96ijgulJSe4AaONG1c6dXVpgmwkNNjfc4M58ly93y//5Z7e+//rXwtdd167uLPKee9x3JBBYIgV3cAd2Tz2VP71bN7fMxo2jn7V17hwM2KGvwAFjYJvbvFn1/vvz53v22eBwvXrBdXD22e4MNvCZXHVV/nmPP969H3OMO+D44Yf8B2qB71FOTvH2fRaQ4vAqaUCKRVaW696Lpc863KpV+fvIc3Nj+40mO9vtdCLZuzf4u1daWuQ8O3e6bpXQvuwNG1zQ+fjjYL02bQp2Ham6HXSk3xI2bHA7j1WrXJ7PPnNdZ0W1YUPkL1FOjju6vusuN56b67ppQs2Z476kofXLzXU7t/D1vGeP614ZMcJ1p3z/vdsR3HGHG168uODfL9LSXNAIlZGh+uuvweHXX3fdayNHujoMH+4ORjZtcl2Lr7/uusDefdd1Da1Z43bYATt35v+tcf58F3yeesptA19/7da5quumnDkzmPeDD9xBTt++7uBo/nzVlStd8M7Jcd1go0e7vBs3uvZ++WWwm0rVHUzNnZu3rXv3ui7Eb78NdmGtWpV/e8zNdfXLycn/mX78cfD3wcD6+ve/Xf0iyc116yc7220jQ4a4A5mXXnLrMyUl+HtXJLt3u27HNWtcd9zSpcHv2eLFrs07d0aeN7QbOvT33P/9z52tTZvmDlBD279pU7ArbtcuV8+FC922MHu2Wx9vvukOIFXd8kOX8+uvwW0p0IX49NPBbT43N+86/e03t/2vXesOSH/6Kfq6iEWsAcn+GFsE9sfYA0t2NiQlgUhZ18SYA1usf4yN5+MnjElolWzrNyah2P+QjDHGJAQLSMYYYxKCBSRjjDEJwQKSMcaYhGAByRhjTEKwgGSMMSYhWEAyxhiTECwgGWOMSQhxDUgi0klElotIqogMjDC9qoiM99O/E5H6IdMG+fTlItKxsDJFpIEvI9WXWcWnnyciC0QkW0S6R6jD4SKSLiIvlXb7jTHGxC5uAUlEkoCXgc5AY6CniDQOy3YzsFlVGwLDgCF+3sZAD6AJ0Al4RUSSCilzCDDMl7XZlw3wK9AHGBulqo8Bs0vWWmOMMSUVzzOk1kCqqq5S1b3AOKBbWJ5uQOAByxOBC0VEfPo4Vd2jqquBVF9exDL9PB18GfgyrwBQ1TRVXQTke16kiLQCagOflVajjTHGFE88A9LxwNqQ8XSfFjGPqmYDW4GaBcwbLb0msMWXEW1ZeYjIQcAzwICYW2SMMSZuKvJFDXcAH6tqekGZRORWEUkRkZSMjIz9VDVjjKl44nm/43VAvZDxuj4tUp50EakEHAFkFjJvpPRMoIaIVPJnSZGWFe5soJ2I3AFUB6qIyHZVzXPxhaqOAEaAe/xEIWUaY4wppnieIc0DGvmr36rgLlKYGpZnKnCDH+4OzPQPc5oK9PBX4TUAGgHfRyvTzzPLl4Ev88OCKqeqvVT1BFWtj+u2ezs8GBljjNl/4haQ/JlKX2AGsAyYoKpLRGSwiHT12d4AaopIKtAfGOjnXQJMAJYCnwJ3qmpOtDJ9WQ8A/X1ZNX3ZiMhZIpIOXA28JiKB/MYYYxKIPTG2COyJscYYU3SxPjG2Il/UYIwxJoFYQDLGGJMQLCAZY4xJCBaQjDHGJAQLSMYYYxKCBSRjjDEJwQKSMcaYhGAByRhjTEKwgGSMMSYhWEAyxhiTECwgGWOMSQgWkIwxxiQEC0jGGGMSggUkY4wxCcECkjHGmIRgAckYY0xCsIBkjDEmIVhAMsYYkxAsIBljjEkIcQ1IItJJRJaLSKqIDIwwvaqIjPfTvxOR+iHTBvn05SLSsbAyRaSBLyPVl1nFp58nIgtEJFtEuofkbyki34jIEhFZJCLXxms9GGOMKVzcApKIJAEvA52BxkBPEWkclu1mYLOqNgSGAUP8vI2BHkAToBPwiogkFVLmEGCYL2uzLxvgV6APMDZs2TuB3qoaWMZzIlKjNNpujDGm6OJ5htQaSFXVVaq6FxgHdAvL0w0Y7YcnAheKiPj0caq6R1VXA6m+vIhl+nk6+DLwZV4BoKppqroIyA1dsKr+oqor/PBvwAagVuk13xhjTFHEMyAdD6wNGU/3aRHzqGo2sBWoWcC80dJrAlt8GdGWFZWItAaqACsjTLtVRFJEJCUjIyPWIo0xxhRRhb+oQUTqAGOAG1U1N3y6qo5Q1WRVTa5Vy06gjDEmXuIZkNYB9ULG6/q0iHlEpBJwBJBZwLzR0jOBGr6MaMvKR0QOB6YDD6rqtzG1yhhjTFzEMyDNAxr5q9+q4C5SmBqWZypwgx/uDsxUVfXpPfxVeA2ARsD30cr088zyZeDL/LCgyvn5PwDeVtWJBeU1xhgTf3ELSP73nL7ADGAZMEFVl4jIYBHp6rO9AdQUkVSgPzDQz7sEmAAsBT4F7lTVnGhl+rIeAPr7smr6shGRs0QkHbgaeE1EAvmvAc4D+ojIQv9qGa/1YYwxpmDiTi5MLJKTkzUlJaWsq2GMMeWKiMxX1eTC8lX4ixqMMcYkBgtIxhhjEoIFJGOMMQnBApIxxpiEYAHJGGNMQrCAZIwxJiFYQDLGGJMQLCAZY4xJCBaQjDHGJAQLSMYYYxKCBSRjjDEJwQKSMcaYhGAByRhjTEKwgGSMMSYhWEAyxhiTECwgGWOMSQgWkIwxxiQEC0jGGGMSQlwDkoh0EpHlIpIqIgMjTK8qIuP99O9EpH7ItEE+fbmIdCysTBFp4MtI9WVW8ennicgCEckWke5hy79BRFb41w3xWAfGGGNiE7eAJCJJwMtAZ6Ax0FNEGodluxnYrKoNgWHAED9vY6AH0AToBLwiIkmFlDkEGObL2uzLBvgV6AOMDavfUcDDQBugNfCwiBxZOq03xhhTVPE8Q2oNpKrqKlXdC4wDuoXl6QaM9sMTgQtFRHz6OFXdo6qrgVRfXsQy/TwdfBn4Mq8AUNU0VV0E5IYtuyPwuapuUtXNwOe44GeMMaYMxDMgHQ+sDRlP92kR86hqNrAVqFnAvNHSawJbfBnRllWc+iEit4pIioikZGRkFFKkMcaY4rKLGgqhqiNUNVlVk2vVqlXW1THGmANWPAPSOqBeyHhdnxYxj4hUAo4AMguYN1p6JlDDlxFtWcWpnzHGmP0kngFpHtDIX/1WBXeRwtSwPFOBwNVt3YGZqqo+vYe/Cq8B0Aj4PlqZfp5Zvgx8mR8WUr8ZwCUicqS/mOESn2aMMaYMxC0g+d9z+uJ28suACaq6REQGi0hXn+0NoKaIpAL9gYF+3iXABGAp8Clwp6rmRCvTl/UA0N+XVdOXjYicJSLpwNXAayKyxC9jE/AYLsjNAwb7NGOMMWVA3MmFiUVycrKmpKSUdTWMMaZcEZH5qppcWD67qMEYY0xCsIBkjDEmIVhAMsYYkxAsIBljjEkIFpCMMcYkBAtIxhhjEoIFJGOMMQnBApIxxpiEYAHJGGNMQrCAZIwxJiFYQDLGGJMQLCAZY4xJCDEFJBE5WUSq+uH2InK3iNSIb9WMMcZUJLGeIU0CckSkITAC92C7sXGrlTHGmAon1oCU659FdCXwoqreB9SJX7WMMcZUNLEGpCwR6Yl7Eus0n1Y5PlUyxhhTEcUakG4Ezgb+o6qr/WPFx8SvWsYYYyqaSrFkUtWlwN0AInIkcJiqDolnxYwxxlQssV5l96WIHC4iRwELgJEi8mwM83USkeUikioiAyNMryoi4/3070Skfsi0QT59uYh0LKxMEWngy0j1ZVYpaBkiUllERovITyKyTEQGxbIujDHGxEesXXZHqOqfwFXA26raBriooBlEJAl4GegMNAZ6ikjjsGw3A5tVtSEwDBji520M9ACaAJ2AV0QkqZAyhwDDfFmbfdlRlwFcDVRV1WZAK+C20IBojDFm/4o1IFUSkTrANQQvaihMayBVVVep6l5gHNAtLE83YLQfnghcKCLi08ep6h5VXQ2k+vIilunn6eDLwJd5RSHLUOBQEakEHAzsBf6MsW3GGGNKWawBaTAwA1ipqvNE5CRgRSHzHA+sDRlP92kR8/jLyrcCNQuYN1p6TWCLLyN8WdGWMRHYAfwO/Ao8raqbwhshIreKSIqIpGRkZBTSZGOMMcUVU0BS1fdVtbmq3u7HV6nqX+NbtbhrDeQAxwENgHt9oM1DVUeoarKqJteqVWt/19EYYyqMWC9qqCsiH4jIBv+aJCJ1C5ltHe6ODgF1fVrEPL7r7Aggs4B5o6VnAjV8GeHLiraM64BPVTVLVTcAXwPJhbTJGGNMnMTaZTcKmIo7mzgO+MinFWQe0Mhf/VYFd5HC1LA8U3F/tgXoDsxUVfXpPfwVcg2ARsD30cr088zyZeDL/LCQZfyK+90JETkUaAv8HOP6MMYYU8piDUi1VHWUqmb711tAgf1X/veavrjfnpYBE1R1iYgMFpGuPtsbQE0RSQX6AwP9vEuACcBS4FPgTlXNiVamL+sBoL8vq6YvO+oycFfrVReRJbhAN0pVF8W4PowxxpQycScLhWQS+S/ujOg9n9QTuFFVL4xj3RJOcnKypqSklHU1jDGmXBGR+apa6E8isZ4h3YS75Hs97qq07kCfYtfOGGOMCRPrVXZrVLWrqtZS1WNU9QqgvF9lZ4wxJoGU5Imx/UutFsYYYyq8kgQkKbVaGGOMqfBKEpAKvxrCGGOMiVGBj58QkW1EDjyCu/+bMcYYUyoKDEiqetj+qogxxpiKrSRddsYYY0ypsYBkjDEmIVhAMsYYkxAsIBljjEkIFpCMMcYkBAtIxhhjEoIFJGOMMQnBApIxxpiEYAHJGGNMQrCAZIwxJiFYQDLGGJMQ4hqQRKSTiCwXkVQRGRhhelURGe+nfyci9UOmDfLpy0WkY2FlikgDX0aqL7NKDMtoLiLfiMgSEflJRKrFZ00YY4wpTNwCkogkAS8DnYHGQE8RaRyW7WZgs6o2BIYBQ/y8jYEeQBOgE/CKiCQVUuYQYJgva7Mvu6BlVALeAf6hqk2A9kBWqa4EY4wxMYvnGVJrIFVVV6nqXmAc0C0sTzdgtB+eCFwoIuLTx6nqHlVdDaT68iKW6efp4MvAl3lFIcu4BFikqj8CqGqmquaUYvuNMcYUQTwD0vHA2pDxdJ8WMY+qZgNbgZoFzBstvSawxZcRvqxoyzgFUBGZISILROT+SI0QkVtFJEVEUjIyMmJsujHGmKKqyBc1VALOBXr59ytF5MLwTKo6QlWTVTW5Vq1a+7uOxhhTYcQzIK0D6oWM1/VpEfP433SOADILmDdaeiZQw5cRvqxoy0gHZqvqRlXdCXwMnFnMthpjjCmheAakeUAjf/VbFdxFClPD8kwFbvDD3YGZqqo+vYe/Qq4B0Aj4PlqZfp5Zvgx8mR8WsowZQDMROcQHqvOBpaXYfmOMMUVQ4CPMS0JVs0WkL27HnwS8qapLRGQwkKKqU4E3gDEikgpswgUYfL4JuACRDdwZuOAgUpl+kQ8A40TkceAHXzYFLGOziDyLC3IKfKyq0+O1PowxxhRM3MmCiUVycrKmpKSUdTWMMaZcEZH5qppcWL6KfFGDMcaYBGIByRhjTEKwgGSMMSYhWEAyxhiTECwgGWOMSQgWkIwxxiQEC0jGGGMSggUkY4wxCcECkjHGmIRgAckYY0xCsIBkjDEmIVhAMqVr9WqYP7+sa2GMKYfidrdvE0d//AG1a5d1LSI76ST3bjftNcYUkZ0hlTcTJ8Kxx8I335R1TYwxplRZQCpvPvTPHVy8uGzrUZgdO8q6BsaYcsYCUnmzdat73727bOsRSXZ2cHjDhrKrhzlwrVkDK1eWdS1MnFhAKm8yM937unVlW49I/vgjOBwpIO3aBenp+68+xbV+PWzbFr/yhw6FH3+MX/kHsvr1oWHDos/31lvughuT0CwglTfr17v3334r23pEsnZtcDg8IH39NXTpAvXqQW6uO8N76aXEO9rdvh3q1HF1jYfdu+H+++Evf4lP+SZIFZ54wnVv33gjtGkT+7yZmXDXXe4gKtEtWJC3d6Ici2tAEpFOIrJcRFJFZGCE6VVFZLyf/p2I1A+ZNsinLxeRjoWVKSINfBmpvswqhS3DTz9BRLaLyIDSXwOlYOfOyF1hq1e7L9yUKW4Hv79MnQqffRZ5WlpacHjVquDwxo1w7rkwa5YbX7/eBaO77oJnnolbVYvlgw/c+5w5ec/4Skvg86tIv7EtXQrDh8OYMbGdpfzwQ97tB+Cnn9yZZVGkpcGDD8Lll7vxjIzY5330UbeNjh1btGXG09q1UL26C0ABy5ZBq1bw0ENlV69SFLeAJCJJwMtAZ6Ax0FNEGodluxnYrKoNgWHAED9vY6AH0AToBLwiIkmFlDkEGObL2uzLjrqMEM8Cn5ROq0vZ2rVw8slw4YWQk+OC0/btbtrChTAkDffmAAAgAElEQVRqFFx5JYwcuf/q1K0bdOwYeVogIB1ySN4uqfCzudWrYckSN7xmTalXMU99vvrK7dyysmKbJ7RL8fff3bsqLFpUsrrk5IAI9O9fsnLKo5Ej4Y47oHdvaNu28Pxnnum2+4wM2LzZpXXu7M4sA2L5W0Hgwp/iBP89e/K+J4LPP3dtCT2ICxw0zZ1bNnUqZfE8Q2oNpKrqKlXdC4wDuoXl6QaM9sMTgQtFRHz6OFXdo6qrgVRfXsQy/TwdfBn4Mq8oZBmIyBXAamBJKba79Eyf7s4mZs92R5mBI7x27VxgmjzZjd95J5xyCvzyy/6rW3Z28Mzs889h0iQXAI4+2p0NLVwYzBsekNLSgoEo/Ei4NHXtCu3bu51bnz7w8MOFzxN6VrRli3sfPhxatHCfA8Ann8C0aUWrS+C3v0mT3HulsL8AfvQRXHFF8DPdXzZudAc28RTafVvYxS733hscPuYYOOooSE3Nvw1F6krbuTPv5xQ4iDjssGCeP/9002fMyHtGH+4gv2uM9UAm3lSD20xguwwdLo0uu4wMePVVSEkpeVnFFM+AdDwQ8qMC6T4tYh5VzQa2AjULmDdaek1giy8jfFkRlyEi1YEHgEcLaoSI3CoiKSKSklGUU/7SEDhCB7fjCHyZr7/enYVMn+7Gc3JgxYqi/TdJNfJG/OuvblnhZb3yCrz/fnC8RQs4+2w3fMkl0L27+4IHfnQOPfOJFJACO4NVq/JfMTh4sOsaLKnA0TW4rpfBg/PvYNavz3sUHLrDDHzZP//cvQcuJLn00mA3UKzCt53QgJSb64Lnhx/CX/9atHJL6oYb4Kab4OefXffP/PkwcyY0a+bWzc6d+c8S0tOLdoFAQUHomWeCAUQVnn02f55GjfKfEQU+m5wcN8/mze6gbdEid4AGwd80AwcD4M7uzz8fOnWC5s2j1ytwsLVpU/Q8keTkwO23F+1vGXv2wBdfuOEpU/Kf7Xz7rQuQn/iOnNCAFFi3OTlFq2ckXbq4uj/4oBvPzXWBez/+yb0iX9TwCK6Lb3tBmVR1hKomq2pyrVq19k/NAgIXMIALEoEdYosWrqsuXEFXsC1YkHfHMnw4VK4cDGrgNsATT4RateCcc/LeAujOO+Gaa4LjS5fC99/nXUYgIB1zjPsiZ2W5L9HAsJ8P09PdzuLss2HvXnj++bztfPhh1zVYXHv3umUfd5wL3DVqBKetWBH88n7xhbuAYfDg4PQ//nB/PIbgJfaBHdru3Xm/nJG6c6ZNgyFD3Bns0Ue7M55162DcuLz5du92X3Yo2hWTH33kAld6OtStC/PmuQOLESPc0X9AVlbeILh8Obz+upv/kktc99nBB8PHH7vpp58OjRtDcrLrIl682J05HXlk8AKMwIFFvXrBO3KECnSNhe/AwgNS4EAhMxMGDHABYvPmvAdghQnslD/+2J1VPfRQsP2Bg47AcgOfI7ide8C2bXDZZa5LUdW1b/t26NXLrU8o2u+IO3a4s7lXX3UHFn/84b5TM2e67Tqaq6+Giy928155pesBSU9335vXXoM333T5Jk4MtmvnTtfu225zaeEHl7t2ue1q8eK8B5Lg2vnSS679WVnu99Latd22BMG6vvqqC9wTJsCnn8b3ytMAVY3LCzgbmBEyPggYFJZnBnC2H64EbAQkPG8gX7Qy/TwbgUrhyy5gGXOANP/aAmwC+hbUplatWmmpeuMN1ebNVZs2VX3tNdVLLlEdPtxNy81Vvfxy1WOOUQXVV15RHThQtVIl1R07VJ96yqWHvv7xj2DZb72l2q+fG/7lFze9enU3nJur2rGjS7vmmuA8l1+et7wzzlD9+mvVLVvyLyvwCp92772uDaD6ySeR50lOdu8jRqh27erqNX686tq1qqNHB/P98kv+dbZ7t+rQoapr1qimpLi2hPrjD9VDDlFt2VK1fn3Vv/1NtVWrvMsfMMDl7d8/WB9V1QULVOvWVT3vPJf+3HMu/aST3PiQIaqffhosp27dvMvOzQ1O++wz93700aqHHhpMHzlSVSRvvkBeUD388GA7A7ZvDw4H8r38sntv21b12Wfd8ODBwXpcdplLW77cpQW2o6K8WrQIDgc+y3/+M29as2aqixapzpvn0oYPd+t/5MhgnY89Nm+5P/zg0idMCKbVquW2N1Dt0KHwul1+uSsj8D3o3Vu1TRs3fNJJqunpqmefHXtbhw1z7wMH5p82ebJb1vTpbrkrV7rxtWvduv7zT9Uzz3R5q1XLO2/79u69c2c3T06O6rp17js8Z07ebeb//i+2ulap4tZ7ePqtt6r+/nvk9ff226rff+/2OYG6gur11+fPX7euana26rXXuvFzz3Xvderk/77FCEhRjSFuxJKpOC+/818FNACqAD8CTcLy3Am86od7ABP8cBOfv6qffxWQVFCZwPtADz/8KnBHQcsIq8cjwIDC2lSigJSdnXd8797oG9zrr6secYRqvXqqF1yg+3Y27dqptm7t5p87N/98l10WLD+QdtxxquefHxzv1y9/MPv1V9WNG6PX5913o0/74IO84y++qDppkhvu0yeYPneu6jffuPqH7oxXrAiOt2yp2r17cLxGDdU9e1SnTlVdtcp92UJ3YuACWKi77847vX9/90UKTatc2eW98ko3Xr163jb26+feH3lE9bvvgulNmuRvf+AL+vrrqkceGUwPbUfo67ff3M46NC2wI733Xvc+ZIhqUpLqdde5gxRQ/fFHN29oG8LL7tJF9bTT8qaddVbe7SH0ddBB0T/X8NdDDxU8PXQbC7z27nU74EqV8qbXru0Cxj33RC5r6NDY6vTww6rnnBPcVmJtS0Gv6tUjpwcCC6ieckpwuH792MpNSgoeGAa2S3ABoTTqHXg1aFCy+Y87zr1XrZp/2pgxxd79lXlAcnXgUuAXYCXwoE8bDHT1w9V8IEkFvgdOCpn3QT/fcqBzQWX69JN8Gam+zKqFLSNk3vgGpPXr3dHm7be7ncoPP7jgEssG8ve/u43j9NODG3LAmjXuaCY0//HHB49oQl8dO6peeKE7ejz+eJcWOBP4299U33nHDTds6N5Dj8ACy47ltWBB5GC5bZurc69ewbTAGdAVVwTTDj7YBabA+IABweGjjsq/E7v9dndW1K9f/jMhcEf04QEJXLAPHQ+cBYHq//6Xd8d02GHuzCUw/sQTwTOQFi1cEDzssNjWz969qmlp+dPPOced8UULEqH1C7yuvtoFr0j5DzssuGMPHOmGv666Ku/49dernnii6oYN7iClTx8X0ALlFXXndvDBwaPxhx9WHTQoOK1LFxeI69d3Z/b9+7vtfMgQt+xI5R11lHt//vmi16U4r3/9K/82FfjuFOeVlFS0/IFgC6onnFDy5UcrO/TVuXPk9MaNi7fv8xIiIB1or2IHpE2bIu8sjz3WdW/07++OMAMBIvToZMqUvOOTJuUtO7CDfuop1+0RyFe/vuoNNwR3xh9+6LrIAtP79HHz9+4dTDv1VNdVlJamunWrO6sL7W6C4JH5oYcGyz7jDNXHH3ddN6rubCaQ/7bb3DICAl0ilSqp7trl0nbsCB5hV67sukRCywh9he+wDz00/xH4xx+75dao4bpFFi50XUlHH52/vOuuC+4oLrvMdc/k5rqdaSBP//7Bs5hrr3V1/vjjvOWIuLOY8eODn3XokXRgpxLwxBOum+vnn90ONrDuhgxxyw5vU/grEMxzc1236pw5qief7ILjKae4+i1YEMxfqZLbod92m2pmpuqMGapPPumm1a2rmpoaedsNPUMMfwUCRKBtgUDxt7+pdusWnJaU5AJxbq5bN6Hb6YMPBpeVkxNsU2D6+eerzp/v1lVurgtWqnnrMWaMao8ekesY6cwt9BU48Jo7V/WOO9xw8+bu/ZNP3MFJIO/LL7vvRegZ3DPPuG0oMH7XXaqXXurWx3/+49LOPTfYfRgI8BA5yH/8seqbb7pegdDu8FNPde+PPOLOxK+8UvWFF9yB7dixecsIPUgJzBf++vJL160Pqhdd5M7wwR3gheZ79FHVTp1c70YJWECKw6tEXXY7drhgcvvtbgNetChyf+zXX7uzqJ9/dl+Q3btVZ81yX/bbbgueaQTk5KjOnOmCx/bt7gsb+NKqup3x22+74dxcF5T69AnuAFeudEHtrrtct124Z55xR+Lz57vfVL76yp2RBI6if/lFdefO/PNNm5b3t4+A9evdOhg3Lm/64sWum+vTT4NpY8a4Nn/0kRsfPtzt6N57z/3m9q9/qd50k+r997t1NHRosK2R7Njh8r35pvvdpXdvt57HjnVnoqtXB/M+/7xr9x13uHW+bJk7iwy0dfdutzMdNMid9S1YEJz3iy/cGdv69aq33OK6u376KfJ6ilbPTZtce7Oz3Wd1441up3HLLaqbN8dWTna2q/9nn0X+PW7DBlf/lJSCyxk/3h0svfWW6uzZ7mwn8Nnu3evqG/DZZ66dOTmunvfc44JaqKws1wX92GOuSzaSiRNd0M7Kijz9k0/cTvnZZ/NPS0tz9br/ftUlS1zwHTDAfV6PPup6KAYMcAdE2dnB7vScHLcdZme772HAu++6ABEqIyPv92zBAlfncFOmuO0gLU21b18XWNPT3fCMGe77OHu22wbvvdfVO9Tw4aqjRrmA0KuX++5F2m+MG+d+ywpMe+cdN9/Gje5g8f33VV991W3TY8a4fDk5rm2B3xl373Z1/fvfXftefjn6+i+iWAOSuLwmFsnJyZpShtfoG2NMeSQi81U1ubB8Ffmyb2OMMQnEApIxxpiEYAHJGGNMQrCAZIwxJiFYQDLGGJMQLCAZY4xJCBaQjDHGJAQLSMYYYxJCpcKzmIJkZWWRnp7O7vBn+hhTDNWqVaNu3bpUrly5rKtizH5nAamE0tPTOeyww6hfvz7+QbTGFIuqkpmZSXp6Og0aNCjr6hiz31mXXQnt3r2bmjVrWjAyJSYi1KxZ0862TYVlAakUWDAypcW2JVORWUAyxhiTECwgHQCqV69eZst+//33Of3007ngggvypKelpTF27NhilXnOOecUmueWW25h6dKlxSq/II888ghPP/10gXmmTJkSl2UbU9FZQDIl8sYbbzBy5EhmzZqVJ72ggJSdnV1gmf/73/8KXe7rr79O48aNY69oKbKAZEx82FV2peiee2DhwtIts2VLeO65os+XlpbGTTfdxMaNG6lVqxajRo3ihBNO4P333+fRRx8lKSmJI444gtmzZ7NkyRJuvPFG9u7dS25uLpMmTaJRo0Z5ynvvvfd44oknUFW6dOnCkCFDGDx4MHPnzuXmm2+ma9euDB06dF/+gQMHsmzZMlq2bMkNN9zAkUceyeTJk9m+fTs5OTlMnz6dbt26sXnzZrKysnj88cfp1q0b4M74tm/fzpdffskjjzzC0UcfzeLFi2nVqhXvvPMOIkL79u15+umnSU5Opnr16vTr149p06Zx8MEH8+GHH1K7dm1WrlxJr1692LFjB926deO5555j+/bt+dbVf/7zH0aPHs0xxxxDvXr1aNWqFQAjR45kxIgR7N27l4YNGzJmzBgWLlzI1KlT+eqrr3j88ceZNGkSM2fOzJfvkEMOKfqHZkxFF8tT/Ir7AjoBy4FUYGCE6VWB8X76d0D9kGmDfPpyoGNhZQINfBmpvswqBS0DuBiYD/zk3zsU1p5IT4xdunTpvuF+/dwTk0vz1a9fYc9iVD300EPzpV122WX61ltvqarqG2+8od26dVNV1aZNm2p6erqqqm72Tx7t27evvvPOO6qqumfPHt0Z9mTTdevWab169XTDhg2alZWlF1xwgX7wwQeqqnr++efrvHnz8i1/1qxZ2qVLl33jo0aN0uOPP14zMzNVVTUrK0u3bt2qqqoZGRl68skna65/2mWgPbNmzdLDDz9c165dqzk5Odq2bVudM2dOvuUCOtU/0fO+++7Txx57TFVVu3TpomPHjlVV1eHDh0dcTykpKdq0aVPdsWOHbt26VU8++WQdOnSoqqpuDHmC7oMPPqgvvPCCqqrecMMN+v777++bFi1fcYVuU8YcCIjxibFxO0MSkSTgZb/jTwfmichUVQ3t67gZ2KyqDUWkBzAEuFZEGgM9gCbAccAXInKKnydamUOAYao6TkRe9WUPj7YMYCNwuar+JiJNgRnA8SVpc3HOZOLlm2++YfLkyQBcf/313H///QD85S9/oU+fPlxzzTVcddVVAJx99tn85z//IT09nauuuirf2dG8efNo3749tWrVAqBXr17Mnj2bK664okh1uvjiiznqqKMAdyD0r3/9i9mzZ3PQQQexbt06/vjjD4499tg887Ru3Zq6desC0LJlS9LS0jj33HPz5KlSpQqXXXYZAK1ateLzzz/ftw6mTJkCwHXXXceAAQPy1WnOnDlceeWV+85ounbtum/a4sWLeeihh9iyZQvbt2+nY8eOEdsVaz5jTMHi+RtSayBVVVep6l5gHNAtLE83YLQfnghcKO66127AOFXdo6qrcWc3raOV6efp4MvAl3lFQctQ1R9U9TefvgQ4WESqllrrE9Srr77K448/ztq1a2nVqhWZmZlcd911TJ06lYMPPphLL72UmTNnxmXZhx566L7hd999l4yMDObPn8/ChQupXbt2xP/fVK0a/EiSkpIi/v5UuXLlfZdLR8tTHH369OGll17ip59+4uGHH476/6BY8xljChbPgHQ8sDZkPJ38ZyD78qhqNrAVqFnAvNHSawJbfBnhy4q2jFB/BRao6p7wRojIrSKSIiIpGRkZhTQ5cZxzzjmMGzcOcDv/du3aAbBy5UratGnD4MGDqVWrFmvXrmXVqlWcdNJJ3H333XTr1o1FixblKat169Z89dVXbNy4kZycHN577z3OP//8Apd/2GGHsW3btqjTt27dyjHHHEPlypWZNWsWa9asKWGL82vbti2TJk0C2Lcuwp133nlMmTKFXbt2sW3bNj766KN907Zt20adOnXIysri3Xff3Zce3rZo+YwxRVPhr7ITkSa4brzbIk1X1RGqmqyqyYEuq0Szc+dO6tatu+/17LPP8uKLLzJq1CiaN2/OmDFjeP755wG47777aNasGU2bNuWcc86hRYsWTJgwgaZNm9KyZUsWL15M796985Rfp04dnnzySS644AJatGhBq1at9l2AEE3z5s1JSkqiRYsWDBs2LN/0Xr16kZKSQrNmzXj77bc57bTTSm+FeM899xzPPvsszZs3JzU1lSOOOCJfnjPPPJNrr72WFi1a0LlzZ84666x90x577DHatGnDX/7ylzz169GjB0OHDuWMM85g5cqVUfMZY4oolh+aivMCzgZmhIwPAgaF5ZkBnO2HK+F+15HwvIF80cr082wEKoUvO9oy/Hhd4BfgL7G0qbCLGkxi2bFjx74LJd577z3t2rVrGdcoNrZNmQMNMV7UEM8zpHlAIxFpICJVcBcpTA3LMxW4wQ93B2b6yk8FeohIVRFpADQCvo9Wpp9nli8DX+aHBS1DRGoA03FX6n1dqi03CWH+/Pm0bNmS5s2b88orr/DMM8+UdZWMMQWI21V2qpotIn1xZyhJwJuqukREBuOi5VTgDWCMiKQCm3ABBp9vArAUyAbuVNUcgEhl+kU+AIwTkceBH3zZRFsG0BdoCPxbRP7t0y5R1Q3xWB9m/2vXrh0//vhjWVfDGBOjQNeViUFycrKmpKTkSVu2bBmnn356GdXIHIhsmzIHGhGZr6rJheWr8Bc1GGOMSQwWkIwxxiQEC0jGGGMSggWkA0AiPn6iqNLS0mjatCkAKSkp3H333RHz1a9fn40bNxZY1hNPPJFnPJbHWRRVaH0LylPcR3AYUxFZQDIlEu3xEyWRnJzMCy+8UOz5wwNSLI+ziAcLSMYUjQWk0nTPPdC+fem+7rmnWFVJS0ujQ4cONG/enAsvvJBff/0VcGc0TZs2pUWLFpx33nkALFmyhNatW+/7z86KFSvylffee+/tu8PDAw88AJDn8RP33Xdfnvw9evRg+vTp+8b79OnDxIkTSUtLo127dpx55pmceeaZEYPFl19+ue9mqZmZmVxyySU0adKEW265hdCrQq+44gpatWpFkyZNGDFiBOAee7Fr1y5atmxJr169gOAZpKpy33330bRpU5o1a8b48eP3La99+/Z0796d0047jV69ehHp6tP58+fTokULWrRowcsvv5xnXUdq08CBA5kzZw4tW7Zk2LBhMbXdmAotln/P2ivGOzWU0fMnEvHxE5MnT9bevXvvK7Nu3bq6c+dO3bFjh+7atUtVVX/55RcNrNPVq1drkyZNVDXvoyvuuusuffTRR1VVddq0aQpoRkaGquq+R1ns3LlTmzRpsu8xEOHrIzA+ceJEveiiizQ7O1vXr1+v9erV099++63Ax1yEatasmX711VeqqjpgwIB99Y3WpvBHcETLF87u1GAONJT14ycqpAR6/kRZP36ic+fO9OvXjz179vDpp59y3nnncfDBB7N161b69u3LwoULSUpK4pdffimwHbNnz97Xji5dunDkkUfum/bCCy/wwQcfALB27VpWrFhBzZrh980Nmjt3Lj179iQpKYnatWtz/vnnM2/ePA4//PBCH3OxZcsWtmzZsu+s8vrrr+eTTz4BICsrK6Y2xZrPmIrKAlIF8+qrr/Ldd98xffp0WrVqxfz587nuuuto06YN06dP59JLL+W1116jQ4cOJVpOtWrVaN++PTNmzGD8+PH06OFukDFs2DBq167Njz/+SG5uLtWqVStW+V9++SVffPEF33zzDYcccgjt27cv0WMfYnnMRTSxtqm02m7Mgcp+QzpAlfXjJwCuvfZaRo0axZw5c+jUqRPgHjtRp04dDjroIMaMGUNOTk6BZZx33nn7Lgz45JNP2Lx5875yjjzySA455BB+/vlnvv32233zVK5cmaysrHxltWvXjvHjx5OTk0NGRgazZ8+mdevWhbYDoEaNGtSoUYO5c+cC5HnMRLQ2hT+moqhtN6aisYB0AEjEx08AXHLJJXz11VdcdNFFVKlSBYA77riD0aNH06JFC37++ec8D+2L5OGHH2b27Nk0adKEyZMnc8IJJwDQqVMnsrOzOf300xk4cCBt27bdN8+tt95K8+bN913UEHDllVfSvHlzWrRoQYcOHXjqqafyPaG2IKNGjeLOO++kZcuWeS56iNam8EdwFLXtxlQ0di+7IrB72Zn9wbYpc6Cxe9kZY4wpVywgGWOMSQgWkEqBdXua0mLbkqnILCCVULVq1cjMzLQdiSkxVSUzM9MuBzcVlv0PqYTq1q1Leno6GRkZZV0VcwCoVq3avj/oGlPRWEAqocqVK9OgQYOyroYxxpR7ce2yE5FOIrJcRFJFZGCE6VVFZLyf/p2I1A+ZNsinLxeRjoWVKSINfBmpvswqxV2GMcaY/S9uAUlEkoCXgc5AY6CniDQOy3YzsFlVGwLDgCF+3sZAD6AJ0Al4RUSSCilzCDDMl7XZl13kZZTuWjDGGBOreJ4htQZSVXWVqu4FxgHhf+/vBoz2wxOBC0VEfPo4Vd2jqquBVF9exDL9PB18GfgyryjmMowxxpSBeP6GdDywNmQ8HWgTLY+qZovIVqCmT/82bN7j/XCkMmsCW1Q1O0L+4ixjHxG5FbjVj24XkeXRm1yoo4GCH3daPhwo7QBrS6KytiSm4rblxFgy2UUNhVDVEcCI0ihLRFJiuX1GojtQ2gHWlkRlbUlM8W5LPLvs1gH1Qsbr+rSIeUSkEnAEkFnAvNHSM4EavozwZRV1GcYYY8pAPAPSPKCRv/qtCu4CgqlheaYCN/jh7sBM/3TBqUAPf4VcA6AR8H20Mv08s3wZ+DI/LOYyjDHGlIG4ddn532v6AjOAJOBNVV0iIoNxj7OdCrwBjBGRVGATLsDg800AlgLZwJ2qmgMQqUy/yAeAcSLyOPCDL5viLCOOSqXrLwEcKO0Aa0uisrYkpri2xR4/YYwxJiHYveyMMcYkBAtIxhhjEoIFpP2gsFsoJRoReVNENojI4pC0o0TkcxFZ4d+P9OkiIi/4ti0SkTPLrub5iUg9EZklIktFZImI9PPp5ao9IlJNRL4XkR99Ox716UW+ZVai8Hdf+UFEpvnxctkWEUkTkZ9EZKGIpPi0crV9BYhIDRGZKCI/i8gyETl7f7bFAlKcSWy3UEo0b+FupxRqIPBfVW0E/NePg2tXI/+6FRi+n+oYq2zgXlVtDLQF7vTrv7y1Zw/QQVVbAC2BTiLSliLeMivB9AOWhYyX57ZcoKotQ/6jU962r4DngU9V9TSgBe7z2X9tUVV7xfEFnA3MCBkfBAwq63rFUO/6wOKQ8eVAHT9cB1juh18DekbKl4gv3N8BLi7P7QEOARbg7lKyEagUvq3hrkQ92w9X8vmkrOse0oa6fufWAZgGSDluSxpwdFhaudu+cP/RXB2+bvdnW+wMKf4i3UIp3y2KyoHaqvq7H14P1PbD5aZ9vqvnDOA7ymF7fBfXQmAD8DmwkhhvmQUEbpmVKJ4D7gdy/XjMt/8i8dqiwGciMl/crcagHG5fQAMgAxjlu1JfF5FD2Y9tsYBkikzd4VC5+r+AiFQHJgH3qOqfodPKS3tUNUdVW+LOLloDp5VxlYpFRC4DNqjq/LKuSyk5V1XPxHVh3Ski54VOLC/bF+7s80xguKqeAewg2D0HxL8tFpDi70C5RdEfIlIHwL9v8OkJ3z4RqYwLRu+q6mSfXG7bo6pbcHcmOZui3zIrEfwF6Coiabg79nfA/XZRHtuCqq7z7xuAD3AHC+Vx+0oH0lX1Oz8+EReg9ltbLCDFXyy3UCoPQm/BFH5rpt7+ipu2wNaQ0/syJyKCu1vHMlV9NmRSuWqPiNQSkRp++GDc72DLKPots8qcqg5S1bqqWh/3fZipqr0oh20RkUNF5LDAMHAJsJhytn0BqOp6YK2InF7HRfgAAAOfSURBVOqTLsTdyWb/taWsf0irCC/gUuAXXJ//g2Vdnxjq+x7wO5CFO2q6Gddn/19gBfAFcJTPK7irCFcCPwHJZV3/sLaci+tiWAQs9K9Ly1t7gOa4W2Itwu3w/u3TT8LdgzEVeB+o6tOr+fFUP/2ksm5DlHa1B6aV17b4Ov/oX0sC3+/ytn2FtKclkOK3synAkfuzLXbrIGOMMQnBuuyMMcYkBAtIxhhjEoIFJGOMMQnBApIxxpiEYAHJGGNMQrCAZEwRiUhNf2fnhSKyXkTWhYxXibGMUSH/94iW504R6VVKdZ4r7o7zgXqOL41yQ8pPD/xPypjissu+jSkBEXkE2K6qT4elC+77lRtxxv1MROYCfVV1YZzKTweaqruLhDHFYmdIxpQSEWko7rlL7+L+JFlHREaISIq4Zxj9OyTvXBFpKSKVRGSLiDwp7llH34jIMT7P4yJyT0j+J8U9E2m5iJzj0w8VkUl+uRP9sloWoc7viMhwf2PQX0Sks08/WERGi3vOz4LA/dl8fYeJyGJxz8C5I6S4e/xNOReJyCklXqGmwrGAZEzpOg33TJ/G6u5xNlDdM3JaABdL5GdhHQF8pe5ZR98AN0UpW1S1NXAfEAhudwHr1T3v6THc3cyjGR/SZfdkSHo94CzgcmCEiFQF7gb2qGoz4HpgjO+OvB04Dmihqs1x96IL+EPdTTlfB/oXUA9jIqpUeBZjTBGsVNWUkPGeInIz7rt2HO4hjUvD5tmlqp/44flAuyhlTw7JU98Pn4t/YJ2q/igiSwqo27VRuuwm+K7F5SKyFvfAtXOBob7cJSLyG9AQuAh4TlVz/LRNUep3aQH1MCYiC0jGlK4dgQERaYR7KmprVd0iIu/g7ssWbm/IcA7Rv5d7YshTHOE/JBf3h+V41c9UENZlZ0z8HA5sA/70t+3vGIdlfA1cAyAizXBnYEV1tb9j8ym47rsVwBygly/3dNyTQlNxDwb8h4gk+WlHlbgFxnh2FGNM/CzAdc/9DKzBBY/S9iLwtogs9ctainuiaiTjRWSXH/5DVQMBch3uDs/VgVtVda+IvAi8JiI/4e763tunv4br0lskItnAcODVOLTLVEB22bcx5Zi4B9ZVUtXdvovwM6CRBh8FXtj87wATVXVKPOtpTCzsDMmY8q068F8fmAS4LdZgZEyisTMkY4wxCcEuajDGGJMQLCAZY4xJCBaQjDHGJAQLSMYYYxKCBSRjjDEJ4f8DWDo2X+HleOEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], \"b\", label=\"Loss of training data\")\n",
    "plt.plot(history.history['val_loss'], \"r\", label=\"Loss of validation data\")\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.layers.core.Reshape object at 0x114cba690>, <keras.layers.convolutional.Conv1D object at 0x114b8eed0>, <keras.layers.convolutional.Conv1D object at 0x114b8ee90>, <keras.layers.pooling.AveragePooling1D object at 0x114b8ee50>, <keras.layers.convolutional.Conv1D object at 0x114b8ecd0>, <keras.layers.convolutional.Conv1D object at 0x114b52b90>, <keras.layers.pooling.GlobalAveragePooling1D object at 0x114cba3d0>, <keras.layers.core.Dropout object at 0x114bc9990>, <keras.layers.core.Dense object at 0x114bd99d0>]\n"
     ]
    }
   ],
   "source": [
    "print(model_m.layers)\n",
    "\n",
    "# print ('\\ncheck layer before softmax output')\n",
    "layer_models = []\n",
    "for i in range(len(model_m.layers)):\n",
    "    layer_models.append(Model(inputs=model_m.input, outputs=model_m.layers[i].output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880/1880 [==============================] - 0s 35us/step\n",
      "score:\n",
      "5.233651405007472e-06\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = create_segments_and_labels(df_test,\n",
    "                                            TIME_PERIODS,\n",
    "                                            STEP_DISTANCE,\n",
    "                                            LABEL)\n",
    "\n",
    "# Set input_shape / reshape for Keras\n",
    "# todo: remove\n",
    "x_test = x_test.reshape(x_test.shape[0], input_shape)\n",
    "\n",
    "x_test = x_test.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "score = model_m.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print('score:')\n",
    "print(score)\n",
    "\n",
    "y_pred_test = model_m.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  7.,  25., 123., 593., 770., 230.,  79.,  42.,   8.,   3.]),\n",
       " array([0.00027889, 0.00030161, 0.00032434, 0.00034706, 0.00036978,\n",
       "        0.0003925 , 0.00041523, 0.00043795, 0.00046067, 0.0004834 ,\n",
       "        0.00050612]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 1.000e+00, 1.380e+02, 5.113e+03, 9.500e+01, 2.000e+00,\n",
       "        2.000e+00, 6.000e+00, 1.000e+00, 1.000e+00]),\n",
       " array([-0.04053565, -0.02866469, -0.01679374, -0.00492278,  0.00694817,\n",
       "         0.01881913,  0.03069009,  0.04256104,  0.054432  ,  0.06630296,\n",
       "         0.07817391]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAEVRJREFUeJzt3X3M3WV9x/H3RyooutgitcOWrTi7LLAomg4x+ofChIKbEKcG3WbDWPrHWOIenMJcgo8JuAcc2XRphK2aKTKcgSiRVdTolimUB3mU9RZwtENbKeIcEQd+98e56g71vr3P3fvc57Rc71dycq7f9bvO73d9e5/2c34P92mqCklSf54y7QlIkqbDAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1atm0J/DTHHnkkbV27dppT0OSDio33njjd6pq5XzjDugAWLt2Ldu2bZv2NCTpoJLkm6OM8xSQJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR16oD+TWAdPNae95mp7Pe+C189lf1KTwYjHQEkuS/JbUluSbKt9R2RZGuS7e15RetPkkuSzCS5NcmLh7azsY3fnmTj0pQkSRrFQk4BvbKqjq+q9W35POC6qloHXNeWAU4D1rXHJuBDMAgM4ALgJcAJwAV7Q0OSNHmLuQZwBrCltbcAZw71f6QGvgIsT3IUcCqwtar2VNVDwFZgwyL2L0lahFEDoIB/SXJjkk2tb1VVPdDa3wJWtfZq4P6h1+5ofXP1P0GSTUm2Jdm2e/fuEacnSVqoUS8Cv7yqdiZ5DrA1ydeHV1ZVJalxTKiqNgObAdavXz+WbUqSftJIRwBVtbM97wI+xeAc/rfbqR3a8642fCdw9NDL17S+ufolSVMwbwAkeUaSn9nbBk4BbgeuBvbeybMRuKq1rwbe3O4GOhF4uJ0quhY4JcmKdvH3lNYnSZqCUU4BrQI+lWTv+I9V1WeT3ABckeQc4JvAG9r4a4DTgRngEeBsgKrak+Q9wA1t3Luras/YKpEkLci8AVBV9wAvnKX/QeDkWfoLOHeObV0GXLbwaUqSxs2vgpCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMjB0CSQ5LcnOTTbfmYJF9NMpPkE0kObf2HteWZtn7t0DbOb/13Jzl13MVIkka3kCOAtwB3DS1fBFxcVc8HHgLOaf3nAA+1/ovbOJIcC5wFHAdsAD6Y5JDFTV+StL9GCoAka4BXAx9uywFOAq5sQ7YAZ7b2GW2Ztv7kNv4M4PKqerSq7gVmgBPGUYQkaeFGPQL4APA24Edt+dnAd6vqsba8A1jd2quB+wHa+ofb+B/3z/IaSdKEzRsASX4N2FVVN05gPiTZlGRbkm27d++exC4lqUujHAG8DHhNkvuAyxmc+vlrYHmSZW3MGmBna+8EjgZo658FPDjcP8trfqyqNlfV+qpav3LlygUXJEkazbwBUFXnV9WaqlrL4CLu56vqN4EvAK9rwzYCV7X21W2Ztv7zVVWt/6x2l9AxwDrg+rFVIklakGXzD5nT24HLk7wXuBm4tPVfCnw0yQywh0FoUFV3JLkCuBN4DDi3qh5fxP4lSYuwoACoqi8CX2zte5jlLp6q+gHw+jle/z7gfQudpCRp/PxNYEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKn5g2AJE9Lcn2SryW5I8m7Wv8xSb6aZCbJJ5Ic2voPa8szbf3aoW2d3/rvTnLqUhUlSZrfKEcAjwInVdULgeOBDUlOBC4CLq6q5wMPAee08ecAD7X+i9s4khwLnAUcB2wAPpjkkHEWI0ka3bwBUAPfb4tPbY8CTgKubP1bgDNb+4y2TFt/cpK0/sur6tGquheYAU4YSxWSpAUb6RpAkkOS3ALsArYC3wC+W1WPtSE7gNWtvRq4H6Ctfxh49nD/LK8Z3temJNuSbNu9e/fCK5IkjWSkAKiqx6vqeGANg0/tv7RUE6qqzVW1vqrWr1y5cql2I0ndW9BdQFX1XeALwEuB5UmWtVVrgJ2tvRM4GqCtfxbw4HD/LK+RJE3YKHcBrUyyvLWfDrwKuItBELyuDdsIXNXaV7dl2vrPV1W1/rPaXULHAOuA68dViCRpYZbNP4SjgC3tjp2nAFdU1aeT3AlcnuS9wM3ApW38pcBHk8wAexjc+UNV3ZHkCuBO4DHg3Kp6fLzlSJJGNW8AVNWtwItm6b+HWe7iqaofAK+fY1vvA9638GlKksbN3wSWpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlT8wZAkqOTfCHJnUnuSPKW1n9Ekq1JtrfnFa0/SS5JMpPk1iQvHtrWxjZ+e5KNS1eWJGk+oxwBPAb8cVUdC5wInJvkWOA84LqqWgdc15YBTgPWtccm4EMwCAzgAuAlwAnABXtDQ5I0efMGQFU9UFU3tfZ/A3cBq4EzgC1t2BbgzNY+A/hIDXwFWJ7kKOBUYGtV7amqh4CtwIaxViNJGtmCrgEkWQu8CPgqsKqqHmirvgWsau3VwP1DL9vR+ubqlyRNwcgBkOSZwCeBP6iq7w2vq6oCahwTSrIpybYk23bv3j2OTUqSZjFSACR5KoN//P+xqv65dX+7ndqhPe9q/TuBo4devqb1zdX/BFW1uarWV9X6lStXLqQWSdICjHIXUIBLgbuq6q+GVl0N7L2TZyNw1VD/m9vdQCcCD7dTRdcCpyRZ0S7+ntL6JElTsGyEMS8Dfhu4Lcktre9PgQuBK5KcA3wTeENbdw1wOjADPAKcDVBVe5K8B7ihjXt3Ve0ZSxWSpAWbNwCq6l+BzLH65FnGF3DuHNu6DLhsIROUJC0NfxNYkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1Kl5AyDJZUl2Jbl9qO+IJFuTbG/PK1p/klySZCbJrUlePPSajW389iQbl6YcSdKoRjkC+Adgwz595wHXVdU64Lq2DHAasK49NgEfgkFgABcALwFOAC7YGxqSpOmYNwCq6kvAnn26zwC2tPYW4Myh/o/UwFeA5UmOAk4FtlbVnqp6CNjKT4aKJGmC9vcawKqqeqC1vwWsau3VwP1D43a0vrn6f0KSTUm2Jdm2e/fu/ZyeJGk+i74IXFUF1Bjmsnd7m6tqfVWtX7ly5bg2K0nax/4GwLfbqR3a867WvxM4emjcmtY3V78kaUr2NwCuBvbeybMRuGqo/83tbqATgYfbqaJrgVOSrGgXf09pfZKkKVk234AkHwdeARyZZAeDu3kuBK5Icg7wTeANbfg1wOnADPAIcDZAVe1J8h7ghjbu3VW174VlSdIEzRsAVfXGOVadPMvYAs6dYzuXAZctaHaSpCXjbwJLUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHVq2bQnoPFZe95npj0FSQcRjwAkqVMTPwJIsgH4a+AQ4MNVdeGk56Anj2ke9dx34auntm9pHCZ6BJDkEOBvgdOAY4E3Jjl2knOQJA1M+hTQCcBMVd1TVT8ELgfOmPAcJElMPgBWA/cPLe9ofZKkCTvg7gJKsgnY1Ba/n+TuRW7ySOA7i9zGgcJaDiC56AmLB309Q6zlwDVqPT8/ysYmHQA7gaOHlte0vh+rqs3A5nHtMMm2qlo/ru1Nk7UcuJ5M9VjLgWvc9Uz6FNANwLokxyQ5FDgLuHrCc5AkMeEjgKp6LMnvA9cyuA30sqq6Y5JzkCQNTPwaQFVdA1wzwV2O7XTSAcBaDlxPpnqs5cA11npSVePcniTpIOFXQUhSp54UAZDkiCRbk2xvzyvmGLexjdmeZOMs669OcvvSz3hui6klyeFJPpPk60nuSDKVr9lIsiHJ3Ulmkpw3y/rDknyirf9qkrVD685v/XcnOXWS857N/taS5FVJbkxyW3s+adJzn81ifjZt/c8l+X6St05qznNZ5PvsBUn+vf09uS3J0yY5930t4n321CRbWg13JTl/QTuuqoP+AbwfOK+1zwMummXMEcA97XlFa68YWv9a4GPA7QdrLcDhwCvbmEOBLwOnTXj+hwDfAJ7X5vA14Nh9xvwe8HetfRbwidY+to0/DDimbeeQKf4sFlPLi4DntvYvAzun+b5abD1D668E/gl468FaC4Nrn7cCL2zLzz6I32dvAi5v7cOB+4C1o+77SXEEwODrJLa09hbgzFnGnApsrao9VfUQsBXYAJDkmcAfAe+dwFzns9+1VNUjVfUFgBp81cZNDH7XYpJG+bqP4RqvBE5OktZ/eVU9WlX3AjNte9Oy37VU1c1V9V+t/w7g6UkOm8is57aYnw1JzgTuZVDPtC2mllOAW6vqawBV9WBVPT6hec9mMbUU8Iwky4CnAz8Evjfqjp8sAbCqqh5o7W8Bq2YZ89O+huI9wF8CjyzZDEe32FoASLIc+HXguqWY5E8xytd9/HhMVT0GPMzgU9iB9lUhi6ll2G8AN1XVo0s0z1Htdz3tQ9LbgXdNYJ6jWMzP5heBSnJtkpuSvG0C8/1pFlPLlcD/AA8A/wn8RVXtGXXHB9xXQcwlyeeAn51l1TuGF6qqkox8a1OS44FfqKo/3Pd851JZqlqGtr8M+DhwSVXds3+z1DgkOQ64iMGnzoPZO4GLq+r77YDgYLYMeDnwKww+9F2X5MaqmvSHpXE4AXgceC6D08BfTvK5Uf/eHzQBUFW/Ote6JN9OclRVPZDkKGDXLMN2Aq8YWl4DfBF4KbA+yX0M/jyek+SLVfUKlsgS1rLXZmB7VX1gDNNdqHm/7mNozI4WVs8CHhzxtZO0mFpIsgb4FPDmqvrG0k93Xoup5yXA65K8H1gO/CjJD6rqb5Z+2rNaTC07gC9V1XcAklwDvJjJHy3vO8+9FlLLm4DPVtX/AruS/BuwnsF1wflN68LHmC+i/DlPvHD6/lnGHMHg/OWK9rgXOGKfMWuZ/kXgRdXC4DrGJ4GnTGn+y9qb7xj+/4LWcfuMOZcnXtC6orWP44kXge9huhfnFlPL8jb+tdN8P42rnn3GvJPpXwRezM9mBYPrY4e37XwOePVBWsvbgb9v7WcAdwIvGHnf035TjukP8NkM0nt7+2Hu/cdwPYP/dWzvuN9hcGFxBjh7lu2sZfoBsN+1MPjkUMBdwC3t8btTqOF04D8Y3Nnwjtb3buA1rf00BneSzADXA88beu072uvuZsJ3MI2zFuDPGJybvWXo8ZyDtZ59tvFOphwAY3if/RaDi9m3M8uHrIOlFuCZrf8OBv/4/8lC9utvAktSp54sdwFJkhbIAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVP/B4nIJ5S3p9yGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = model_m.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00e+00, 0.00e+00, 2.00e+00, 6.00e+00, 2.00e+02, 4.79e+03,\n",
       "        3.41e+02, 1.40e+01, 4.00e+00, 2.00e+00]),\n",
       " array([-1.54617213e-04, -6.02322834e-05,  3.41526465e-05,  1.28537577e-04,\n",
       "         2.22922507e-04,  3.17307436e-04,  4.11692366e-04,  5.06077296e-04,\n",
       "         6.00462226e-04,  6.94847156e-04,  7.89232086e-04]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
